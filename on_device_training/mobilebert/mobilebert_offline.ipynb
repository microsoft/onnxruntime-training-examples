{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import onnx\n",
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForMaskedLM: ['mobilebert.encoder.layer.16.attention.self.value.weight', 'mobilebert.encoder.layer.2.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.6.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.23.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.5.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.12.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.14.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.22.bottleneck.input.dense.bias', 'cls.seq_relationship.weight', 'mobilebert.encoder.layer.10.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.17.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.12.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.2.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.7.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.attention.output.dense.weight', 'mobilebert.encoder.layer.12.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.15.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.4.output.dense.bias', 'mobilebert.encoder.layer.7.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.10.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.14.attention.self.key.weight', 'mobilebert.encoder.layer.5.intermediate.dense.bias', 'mobilebert.encoder.layer.10.output.LayerNorm.weight', 'mobilebert.encoder.layer.21.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.23.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.14.output.dense.bias', 'mobilebert.encoder.layer.7.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.14.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.3.attention.output.dense.weight', 'mobilebert.encoder.layer.23.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.20.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.12.attention.self.query.weight', 'mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.15.attention.self.key.bias', 'mobilebert.encoder.layer.17.output.dense.bias', 'mobilebert.encoder.layer.23.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.20.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.18.attention.self.query.bias', 'mobilebert.encoder.layer.22.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.12.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.10.intermediate.dense.bias', 'mobilebert.encoder.layer.13.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.4.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.14.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.19.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.2.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.4.attention.self.value.bias', 'mobilebert.encoder.layer.13.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.20.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.17.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.output.dense.bias', 'mobilebert.encoder.layer.19.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.3.output.dense.bias', 'mobilebert.encoder.layer.22.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.10.attention.output.dense.weight', 'mobilebert.encoder.layer.20.output.dense.bias', 'mobilebert.encoder.layer.22.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.5.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.11.intermediate.dense.weight', 'mobilebert.encoder.layer.15.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.attention.self.value.bias', 'mobilebert.encoder.layer.2.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.13.attention.self.key.weight', 'mobilebert.encoder.layer.15.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.5.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.15.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.10.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.19.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.11.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.17.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.4.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.16.output.dense.bias', 'mobilebert.encoder.layer.4.attention.self.value.weight', 'mobilebert.encoder.layer.17.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.2.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.4.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.18.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.18.attention.self.value.bias', 'mobilebert.encoder.layer.18.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.14.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.17.intermediate.dense.bias', 'mobilebert.encoder.layer.23.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.18.attention.output.dense.weight', 'mobilebert.encoder.layer.20.attention.output.dense.weight', 'mobilebert.encoder.layer.7.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.10.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.15.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.6.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.7.attention.self.value.bias', 'mobilebert.encoder.layer.15.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.15.attention.self.query.bias', 'mobilebert.encoder.layer.9.attention.self.value.bias', 'mobilebert.encoder.layer.13.output.LayerNorm.weight', 'mobilebert.encoder.layer.21.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.12.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.8.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.6.output.LayerNorm.bias', 'mobilebert.encoder.layer.15.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.11.output.dense.weight', 'mobilebert.encoder.layer.15.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.20.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.8.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.19.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.5.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.20.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.23.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.18.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.7.attention.self.query.bias', 'mobilebert.encoder.layer.2.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.14.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.15.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.4.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.10.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.8.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.4.attention.self.key.bias', 'mobilebert.encoder.layer.16.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.2.attention.self.key.weight', 'mobilebert.encoder.layer.16.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.16.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.attention.self.key.bias', 'mobilebert.encoder.layer.13.intermediate.dense.bias', 'mobilebert.encoder.layer.16.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.9.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.22.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.5.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.14.output.dense.weight', 'mobilebert.encoder.layer.19.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.4.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.3.attention.self.key.bias', 'mobilebert.encoder.layer.17.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.5.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.16.intermediate.dense.weight', 'mobilebert.encoder.layer.8.output.dense.weight', 'mobilebert.encoder.layer.18.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.15.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.18.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.3.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.6.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.14.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.attention.self.value.bias', 'mobilebert.encoder.layer.4.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.4.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.6.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.23.attention.self.key.bias', 'mobilebert.encoder.layer.3.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.18.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.10.attention.self.value.bias', 'mobilebert.encoder.layer.13.output.dense.weight', 'mobilebert.encoder.layer.18.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.intermediate.dense.bias', 'mobilebert.encoder.layer.17.attention.self.key.weight', 'mobilebert.encoder.layer.2.attention.self.query.weight', 'mobilebert.encoder.layer.15.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.18.attention.self.query.weight', 'mobilebert.encoder.layer.11.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.13.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.14.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.8.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.6.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.16.attention.output.dense.bias', 'mobilebert.encoder.layer.22.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.8.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.18.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.22.attention.self.key.bias', 'mobilebert.encoder.layer.10.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.21.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.21.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.4.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.5.output.LayerNorm.bias', 'mobilebert.encoder.layer.15.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.21.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.6.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.8.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.attention.self.value.bias', 'mobilebert.encoder.layer.11.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.2.output.dense.bias', 'mobilebert.encoder.layer.18.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.attention.self.value.bias', 'mobilebert.encoder.layer.5.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.15.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.21.attention.self.query.bias', 'mobilebert.encoder.layer.11.attention.self.value.weight', 'mobilebert.encoder.layer.2.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.17.attention.self.query.bias', 'mobilebert.encoder.layer.15.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.19.attention.self.query.bias', 'mobilebert.encoder.layer.8.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.3.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.6.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.intermediate.dense.bias', 'mobilebert.encoder.layer.3.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.15.attention.self.value.weight', 'mobilebert.encoder.layer.23.attention.output.dense.weight', 'mobilebert.encoder.layer.10.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.22.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.17.intermediate.dense.weight', 'mobilebert.encoder.layer.4.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.6.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.3.intermediate.dense.weight', 'mobilebert.encoder.layer.15.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.5.attention.output.dense.weight', 'mobilebert.encoder.layer.20.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.2.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.21.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.13.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.13.intermediate.dense.weight', 'mobilebert.encoder.layer.6.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.2.attention.self.query.bias', 'mobilebert.encoder.layer.18.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.12.attention.output.dense.bias', 'mobilebert.encoder.layer.10.attention.self.query.bias', 'mobilebert.encoder.layer.16.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.18.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.22.attention.self.query.bias', 'mobilebert.encoder.layer.5.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.7.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.10.attention.self.key.weight', 'mobilebert.encoder.layer.20.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.19.output.dense.bias', 'mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.20.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.12.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.20.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.2.attention.self.value.bias', 'mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.16.attention.self.query.bias', 'mobilebert.encoder.layer.14.attention.self.value.weight', 'mobilebert.encoder.layer.6.intermediate.dense.weight', 'mobilebert.encoder.layer.13.attention.self.query.weight', 'mobilebert.encoder.layer.17.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.7.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.10.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.9.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.13.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.12.attention.self.key.weight', 'mobilebert.encoder.layer.14.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.4.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.12.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.14.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.9.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.output.LayerNorm.bias', 'mobilebert.encoder.layer.10.attention.output.dense.bias', 'mobilebert.encoder.layer.7.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.22.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.attention.self.value.bias', 'mobilebert.encoder.layer.3.output.LayerNorm.weight', 'mobilebert.encoder.layer.22.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.8.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.8.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.10.attention.self.key.bias', 'mobilebert.encoder.layer.15.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.12.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.7.attention.self.key.weight', 'mobilebert.encoder.layer.13.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.5.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.12.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.7.intermediate.dense.bias', 'mobilebert.encoder.layer.4.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.4.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.19.attention.self.key.bias', 'mobilebert.encoder.layer.10.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.11.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.23.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.5.output.dense.bias', 'mobilebert.encoder.layer.3.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.14.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.5.intermediate.dense.weight', 'mobilebert.encoder.layer.20.attention.self.key.bias', 'mobilebert.encoder.layer.15.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.6.intermediate.dense.bias', 'mobilebert.encoder.layer.9.output.dense.bias', 'mobilebert.encoder.layer.18.intermediate.dense.bias', 'mobilebert.encoder.layer.10.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.22.intermediate.dense.weight', 'mobilebert.encoder.layer.12.intermediate.dense.weight', 'mobilebert.encoder.layer.6.attention.self.key.weight', 'mobilebert.encoder.layer.18.output.dense.bias', 'mobilebert.encoder.layer.19.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.10.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.23.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.21.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.13.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.23.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.22.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.13.output.dense.bias', 'mobilebert.encoder.layer.16.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.23.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.5.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.23.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.14.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.18.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.13.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.17.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.attention.self.key.bias', 'mobilebert.encoder.layer.11.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.11.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.6.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.20.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.22.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.18.output.dense.weight', 'mobilebert.encoder.layer.7.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.11.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.9.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.7.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.7.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.2.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.20.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.9.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.14.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.14.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.19.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.6.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.6.output.dense.weight', 'mobilebert.encoder.layer.14.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.18.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.3.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.14.attention.self.query.weight', 'mobilebert.encoder.layer.7.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.7.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.intermediate.dense.weight', 'mobilebert.encoder.layer.17.output.dense.weight', 'mobilebert.encoder.layer.8.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.8.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.16.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.9.attention.self.query.bias', 'mobilebert.encoder.layer.2.output.dense.weight', 'mobilebert.encoder.layer.18.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.21.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.7.output.dense.weight', 'mobilebert.encoder.layer.16.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.22.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.2.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.14.attention.self.key.bias', 'mobilebert.encoder.layer.10.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.23.intermediate.dense.bias', 'mobilebert.encoder.layer.7.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.15.output.dense.weight', 'mobilebert.encoder.layer.9.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.21.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.13.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.4.intermediate.dense.bias', 'mobilebert.encoder.layer.8.intermediate.dense.weight', 'mobilebert.encoder.layer.18.intermediate.dense.weight', 'mobilebert.encoder.layer.20.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.23.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.22.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.18.attention.self.key.weight', 'mobilebert.encoder.layer.11.attention.self.value.bias', 'mobilebert.encoder.layer.15.attention.output.dense.weight', 'mobilebert.encoder.layer.8.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.5.attention.self.value.bias', 'mobilebert.encoder.layer.9.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.19.attention.output.dense.bias', 'mobilebert.encoder.layer.18.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.21.output.dense.bias', 'mobilebert.encoder.layer.4.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.4.attention.self.key.weight', 'mobilebert.encoder.layer.3.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.12.attention.self.query.bias', 'mobilebert.encoder.layer.18.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.5.attention.output.dense.bias', 'mobilebert.encoder.layer.7.attention.self.key.bias', 'mobilebert.encoder.layer.2.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.11.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.11.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.10.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.10.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.18.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.5.attention.self.query.weight', 'mobilebert.encoder.layer.12.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.12.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.13.attention.self.key.bias', 'mobilebert.encoder.layer.16.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.17.attention.self.value.bias', 'mobilebert.encoder.layer.6.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.18.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.19.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.attention.output.dense.weight', 'mobilebert.encoder.layer.7.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.4.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.13.attention.self.value.bias', 'mobilebert.encoder.layer.21.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.22.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.2.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.17.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.20.attention.self.value.weight', 'mobilebert.encoder.layer.21.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.18.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.14.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.21.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.2.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.17.attention.output.dense.bias', 'mobilebert.encoder.layer.8.attention.self.value.weight', 'mobilebert.encoder.layer.19.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.6.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.17.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.19.intermediate.dense.weight', 'mobilebert.encoder.layer.6.attention.self.value.weight', 'mobilebert.encoder.layer.18.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.17.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.13.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.7.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.13.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.22.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.5.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.14.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.15.attention.output.dense.bias', 'mobilebert.encoder.layer.8.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.21.attention.self.key.weight', 'mobilebert.encoder.layer.8.attention.output.dense.bias', 'mobilebert.encoder.layer.22.intermediate.dense.bias', 'mobilebert.encoder.layer.16.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.5.attention.self.value.weight', 'mobilebert.encoder.layer.5.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.10.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.17.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.17.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.19.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.15.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.19.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.23.intermediate.dense.weight', 'mobilebert.encoder.layer.3.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.attention.output.dense.weight', 'mobilebert.encoder.layer.14.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.12.intermediate.dense.bias', 'mobilebert.encoder.layer.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.12.output.dense.bias', 'mobilebert.encoder.layer.20.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.16.output.LayerNorm.weight', 'mobilebert.encoder.layer.2.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.11.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.4.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.19.attention.self.value.weight', 'mobilebert.encoder.layer.10.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.13.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.20.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.20.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.7.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.10.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.8.attention.output.dense.weight', 'mobilebert.encoder.layer.16.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.5.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.8.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.9.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.11.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.5.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.9.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.2.attention.output.dense.bias', 'mobilebert.encoder.layer.19.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.5.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.2.intermediate.dense.bias', 'mobilebert.encoder.layer.23.attention.self.key.weight', 'mobilebert.encoder.layer.5.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.6.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.22.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.15.attention.self.value.bias', 'mobilebert.encoder.layer.2.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.10.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.15.intermediate.dense.bias', 'mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.8.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.21.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.8.intermediate.dense.bias', 'mobilebert.encoder.layer.17.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.17.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.23.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.7.intermediate.dense.weight', 'mobilebert.encoder.layer.15.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.2.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.8.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.8.attention.self.key.bias', 'mobilebert.encoder.layer.16.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.6.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.7.attention.output.dense.weight', 'mobilebert.encoder.layer.23.attention.self.query.bias', 'mobilebert.encoder.layer.7.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.22.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.3.attention.self.value.bias', 'mobilebert.encoder.layer.12.output.LayerNorm.bias', 'mobilebert.encoder.layer.2.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.13.attention.output.dense.weight', 'mobilebert.encoder.layer.17.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.7.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.attention.output.dense.weight', 'mobilebert.encoder.layer.6.attention.self.key.bias', 'mobilebert.encoder.layer.2.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.13.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.18.output.LayerNorm.bias', 'mobilebert.encoder.layer.5.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.8.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.14.intermediate.dense.weight', 'mobilebert.encoder.layer.22.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.output.dense.bias', 'mobilebert.encoder.layer.21.attention.self.value.weight', 'mobilebert.encoder.layer.11.attention.self.key.bias', 'mobilebert.encoder.layer.6.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.2.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.3.attention.output.dense.bias', 'mobilebert.encoder.layer.10.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.9.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.2.attention.output.dense.weight', 'mobilebert.encoder.layer.11.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.2.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.17.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.4.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.19.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.10.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.21.attention.output.dense.bias', 'mobilebert.encoder.layer.17.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.5.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.5.attention.self.query.bias', 'mobilebert.encoder.layer.10.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.15.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.22.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.8.attention.self.query.weight', 'mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.9.attention.self.query.weight', 'mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.18.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.18.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.4.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.23.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.9.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.12.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.16.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.7.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.18.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.3.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.9.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.11.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.11.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.6.attention.self.query.bias', 'mobilebert.encoder.layer.9.output.dense.weight', 'mobilebert.encoder.layer.2.intermediate.dense.weight', 'mobilebert.encoder.layer.9.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.16.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.14.output.LayerNorm.weight', 'mobilebert.encoder.layer.5.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.attention.self.key.weight', 'mobilebert.encoder.layer.20.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.6.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.5.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.15.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.11.output.dense.bias', 'mobilebert.encoder.layer.12.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.6.output.dense.bias', 'mobilebert.encoder.layer.22.attention.self.key.weight', 'mobilebert.encoder.layer.22.output.LayerNorm.weight', 'mobilebert.encoder.layer.9.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.4.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.20.attention.self.value.bias', 'mobilebert.encoder.layer.23.attention.self.value.weight', 'mobilebert.encoder.layer.19.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.18.attention.self.key.bias', 'mobilebert.encoder.layer.13.attention.output.dense.bias', 'mobilebert.encoder.layer.22.attention.self.query.weight', 'mobilebert.encoder.layer.4.intermediate.dense.weight', 'mobilebert.encoder.layer.16.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.13.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.2.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.15.output.dense.bias', 'mobilebert.encoder.layer.21.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.3.output.dense.weight', 'mobilebert.encoder.layer.7.output.dense.bias', 'mobilebert.encoder.layer.19.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.18.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.20.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.attention.self.query.weight', 'mobilebert.encoder.layer.19.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.7.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.9.attention.output.dense.bias', 'mobilebert.encoder.layer.8.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.11.attention.self.key.weight', 'mobilebert.encoder.layer.16.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.9.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.13.attention.self.value.weight', 'mobilebert.encoder.layer.4.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.20.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.9.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.attention.self.query.weight', 'mobilebert.encoder.layer.5.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.8.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.output.dense.weight', 'mobilebert.encoder.layer.4.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.9.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.18.output.LayerNorm.weight', 'mobilebert.encoder.layer.13.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.11.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.22.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.22.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.3.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.22.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.14.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.17.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.19.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.14.attention.self.value.bias', 'mobilebert.encoder.layer.5.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.output.LayerNorm.weight', 'mobilebert.encoder.layer.21.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.20.attention.output.dense.bias', 'mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.14.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.6.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.9.attention.self.value.weight', 'mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.23.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.3.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.22.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.20.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.3.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.9.attention.self.key.bias', 'mobilebert.encoder.layer.23.output.dense.weight', 'mobilebert.encoder.layer.17.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.6.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.5.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.20.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.4.attention.output.dense.weight', 'mobilebert.encoder.layer.18.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.5.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.attention.output.dense.weight', 'mobilebert.encoder.layer.2.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.7.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.5.attention.self.key.weight', 'mobilebert.encoder.layer.8.output.LayerNorm.weight', 'mobilebert.encoder.layer.11.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.11.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.23.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.10.attention.self.value.weight', 'mobilebert.encoder.layer.12.output.dense.weight', 'mobilebert.encoder.layer.23.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.14.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.9.intermediate.dense.weight', 'mobilebert.encoder.layer.23.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.2.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.14.attention.output.dense.weight', 'mobilebert.encoder.layer.13.attention.self.query.bias', 'mobilebert.encoder.layer.6.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.4.attention.self.query.bias', 'mobilebert.encoder.layer.8.attention.self.key.weight', 'mobilebert.encoder.layer.22.attention.output.dense.weight', 'mobilebert.encoder.layer.23.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.15.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.10.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.2.attention.self.value.weight', 'mobilebert.encoder.layer.5.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.17.output.LayerNorm.weight', 'mobilebert.encoder.layer.3.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.7.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.10.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.13.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.15.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.9.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.21.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.4.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.14.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.13.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.17.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.2.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.13.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.17.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.output.dense.weight', 'mobilebert.encoder.layer.6.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.21.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.22.attention.output.dense.bias', 'mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.12.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.3.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.21.attention.self.value.bias', 'mobilebert.encoder.layer.3.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.11.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.20.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.4.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.8.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.attention.self.key.weight', 'mobilebert.encoder.layer.10.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.11.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.19.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.18.attention.self.value.weight', 'mobilebert.encoder.layer.19.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.8.output.dense.bias', 'mobilebert.encoder.layer.4.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.16.output.dense.weight', 'mobilebert.encoder.layer.13.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.15.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.21.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.21.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.23.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.18.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.8.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.10.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.8.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.12.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.12.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.21.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.14.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.19.attention.self.value.bias', 'mobilebert.encoder.layer.4.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.7.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.23.attention.output.dense.bias', 'mobilebert.encoder.layer.14.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.10.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.21.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.5.output.dense.weight', 'mobilebert.encoder.layer.19.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.21.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.14.attention.self.query.bias', 'mobilebert.encoder.layer.4.attention.self.query.weight', 'mobilebert.encoder.layer.4.attention.output.dense.bias', 'mobilebert.encoder.layer.5.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.22.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.23.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.18.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.8.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.20.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.15.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.23.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.5.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.2.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.11.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.23.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.3.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.4.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.8.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.13.ffn.0.output.dense.weight', 'mobilebert.encoder.layer.9.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.21.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.19.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.12.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.14.attention.output.dense.bias', 'mobilebert.encoder.layer.21.attention.self.key.bias', 'mobilebert.encoder.layer.11.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.14.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.18.attention.output.dense.bias', 'mobilebert.encoder.layer.16.intermediate.dense.bias', 'mobilebert.encoder.layer.4.output.LayerNorm.bias', 'mobilebert.encoder.layer.6.attention.output.dense.bias', 'mobilebert.encoder.layer.20.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.11.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.8.attention.self.value.bias', 'mobilebert.encoder.layer.9.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.23.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.20.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.17.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.17.attention.self.query.weight', 'mobilebert.encoder.layer.21.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.6.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.4.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.22.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.10.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.21.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.4.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.10.intermediate.dense.weight', 'mobilebert.encoder.layer.13.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.20.attention.self.query.bias', 'mobilebert.encoder.layer.5.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.14.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.14.output.LayerNorm.bias', 'mobilebert.encoder.layer.6.attention.output.dense.weight', 'mobilebert.encoder.layer.13.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.attention.self.value.weight', 'mobilebert.encoder.layer.19.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.21.output.dense.weight', 'mobilebert.encoder.layer.2.attention.self.key.bias', 'mobilebert.encoder.layer.2.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.15.output.LayerNorm.weight', 'mobilebert.encoder.layer.20.attention.self.query.weight', 'mobilebert.encoder.layer.22.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.7.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.16.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.7.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.12.ffn.2.output.LayerNorm.weight', 'mobilebert.encoder.layer.9.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.22.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.23.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.5.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.11.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.4.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.11.attention.output.dense.bias', 'mobilebert.encoder.layer.14.intermediate.dense.bias', 'mobilebert.encoder.layer.14.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.23.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.16.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.17.attention.self.value.weight', 'mobilebert.encoder.layer.15.attention.self.key.weight', 'mobilebert.encoder.layer.11.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.8.output.bottleneck.dense.weight', 'cls.seq_relationship.bias', 'mobilebert.encoder.layer.23.output.LayerNorm.weight', 'mobilebert.encoder.layer.15.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.9.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.3.attention.self.key.weight', 'mobilebert.encoder.layer.6.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.7.attention.output.dense.bias', 'mobilebert.encoder.layer.15.intermediate.dense.weight', 'mobilebert.encoder.layer.19.ffn.2.intermediate.dense.weight', 'mobilebert.encoder.layer.21.intermediate.dense.bias', 'mobilebert.encoder.layer.11.intermediate.dense.bias', 'mobilebert.encoder.layer.8.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.9.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.11.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.4.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.10.bottleneck.input.dense.weight', 'mobilebert.encoder.layer.17.bottleneck.attention.dense.weight', 'mobilebert.encoder.layer.9.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.8.attention.self.query.bias', 'mobilebert.encoder.layer.3.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.14.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.16.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.21.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.2.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm.weight', 'mobilebert.encoder.layer.14.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.attention.self.query.weight', 'mobilebert.encoder.layer.22.output.dense.weight', 'mobilebert.encoder.layer.3.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.22.attention.self.value.weight', 'mobilebert.encoder.layer.8.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.19.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.21.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.9.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.8.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.19.attention.self.query.weight', 'mobilebert.encoder.layer.14.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.3.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.4.output.LayerNorm.weight', 'mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.16.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.18.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.20.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.6.attention.self.query.weight', 'mobilebert.encoder.layer.12.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.4.output.dense.weight', 'mobilebert.encoder.layer.5.attention.self.key.bias', 'mobilebert.encoder.layer.16.attention.self.query.weight', 'mobilebert.encoder.layer.9.attention.output.dense.weight', 'mobilebert.encoder.layer.11.attention.self.query.bias', 'mobilebert.encoder.layer.10.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.3.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.20.intermediate.dense.weight', 'mobilebert.encoder.layer.12.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.12.attention.self.key.bias', 'mobilebert.encoder.layer.13.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.16.attention.output.dense.weight', 'mobilebert.encoder.layer.9.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.4.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.19.attention.self.key.weight', 'mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.11.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.20.intermediate.dense.bias', 'mobilebert.encoder.layer.8.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.2.ffn.1.output.dense.weight', 'mobilebert.encoder.layer.3.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.23.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.20.attention.self.key.weight', 'mobilebert.encoder.layer.7.attention.self.query.weight', 'mobilebert.encoder.layer.10.output.dense.weight', 'mobilebert.encoder.layer.9.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.23.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.13.output.bottleneck.LayerNorm.weight', 'mobilebert.encoder.layer.10.output.dense.bias', 'mobilebert.encoder.layer.18.attention.output.LayerNorm.bias', 'mobilebert.encoder.layer.5.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.10.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.8.bottleneck.input.LayerNorm.weight', 'mobilebert.encoder.layer.19.ffn.1.output.LayerNorm.weight', 'mobilebert.encoder.layer.21.attention.self.query.weight', 'mobilebert.encoder.layer.23.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.9.output.bottleneck.dense.bias', 'mobilebert.encoder.layer.21.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm.bias', 'mobilebert.encoder.layer.6.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.6.ffn.2.intermediate.dense.bias', 'mobilebert.encoder.layer.3.intermediate.dense.bias', 'mobilebert.encoder.layer.19.output.LayerNorm.weight', 'mobilebert.encoder.layer.19.output.LayerNorm.bias', 'mobilebert.encoder.layer.17.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.18.ffn.0.intermediate.dense.weight', 'mobilebert.encoder.layer.20.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.11.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.7.attention.self.value.weight', 'mobilebert.encoder.layer.17.output.bottleneck.dense.weight', 'mobilebert.encoder.layer.2.ffn.1.output.LayerNorm.bias', 'mobilebert.encoder.layer.12.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.10.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.14.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.20.ffn.1.intermediate.dense.weight', 'mobilebert.encoder.layer.21.ffn.0.output.dense.bias', 'mobilebert.encoder.layer.11.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.12.ffn.2.output.dense.weight', 'mobilebert.encoder.layer.13.bottleneck.input.LayerNorm.bias', 'mobilebert.encoder.layer.8.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.3.ffn.0.intermediate.dense.bias', 'mobilebert.encoder.layer.7.bottleneck.attention.dense.bias', 'mobilebert.encoder.layer.13.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.15.output.bottleneck.LayerNorm.bias', 'mobilebert.encoder.layer.2.attention.output.LayerNorm.weight', 'mobilebert.encoder.layer.5.ffn.1.intermediate.dense.bias', 'mobilebert.encoder.layer.10.attention.self.query.weight', 'mobilebert.encoder.layer.19.ffn.2.output.dense.bias', 'mobilebert.encoder.layer.3.attention.self.query.bias', 'mobilebert.encoder.layer.17.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.6.bottleneck.input.dense.bias', 'mobilebert.encoder.layer.19.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.15.attention.self.query.weight', 'mobilebert.encoder.layer.3.attention.self.value.weight', 'mobilebert.encoder.layer.19.ffn.0.output.LayerNorm.bias', 'mobilebert.encoder.layer.11.ffn.0.output.LayerNorm.weight', 'mobilebert.encoder.layer.9.ffn.2.output.LayerNorm.bias', 'mobilebert.encoder.layer.20.ffn.1.output.dense.bias', 'mobilebert.encoder.layer.7.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertConfig\n",
    "config = MobileBertConfig(num_hidden_layers=2)\n",
    "model = transformers.MobileBertForMaskedLM.from_pretrained('google/mobilebert-uncased', config=config)\n",
    "# model = transformers.AutoModel.from_pretrained('google/mobilebert-uncased')\n",
    "model_name = 'mobilebert-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, *local_inputs):\n",
    "        return self.model(inputs.input_ids, inputs.attention_mask, inputs.token_type_ids, labels=labels)\n",
    "\n",
    "model = FlatModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(1000),\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:967: UserWarning: Warning: ONNX export of embedding with padding_idx >= 0 for training mode. ONNX does not support not updating the embedding vector at padding_idx during training.\n",
      "  warnings.warn(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], \n",
    "      inputs[\"attention_mask\"],\n",
    "      inputs[\"token_type_ids\"],\n",
    "      labels),\n",
    "    f\"model.onnx\",\n",
    "    input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"],\n",
    "    output_names=[\"loss\", \"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"token_type_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"labels\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits \": {0: \"batch_size\", 1: \"sequence_length\"}\n",
    "    },\n",
    "    export_params=True,\n",
    "    do_constant_folding=False,\n",
    "    training=torch.onnx.TrainingMode.TRAINING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 20:28:03.888548843 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/cls/predictions/transform/LayerNorm/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.888612040 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/cls/predictions/transform/LayerNorm/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893525029 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Transpose_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893539528 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Slice_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893544728 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Reshape_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893549328 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Concat_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893553928 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/ConstantOfShape_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893558428 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Sub_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893562927 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_24_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893567427 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_11_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893571927 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893576727 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893580827 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Cast_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893585426 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Sub_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893589726 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Shape_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893593826 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_31_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893598226 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_29_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893602426 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_27_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893606626 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_238'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893611625 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_26_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893636124 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Shape_167'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893643824 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Shape_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893648024 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_23_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893652824 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Slice_4_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893656923 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893661123 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Shape_138'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893665223 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_236'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893669923 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_253'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893674123 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_255'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893678722 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_17_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893682822 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Mul_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893686722 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893690522 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893694622 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_25_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893698922 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_30_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893704221 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_16_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893708621 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_28_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893712721 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_12_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893716721 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/ConstantOfShape_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893720721 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893725020 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Mul_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893730220 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Gather_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893734420 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_269'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893738520 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_271'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893742920 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_9_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893747020 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_11_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893751719 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Reshape_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893756119 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_299'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893760419 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_388'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893764719 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_390'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893769119 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Cast_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893773118 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_405'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893777118 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_407'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893781718 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_10_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893785718 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_421'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893789718 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_423'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893794417 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Reshape_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893798517 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_450'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893802417 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Gather_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893806717 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_13_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893810717 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_14_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893817117 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Concat_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893821216 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Transpose_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893825416 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Reshape_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.893829416 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/Constant_15_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.894055806 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "2023-04-06 20:28:03.894077705 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.0/attention/self/Reshape_output_0\n",
      "2023-04-06 20:28:03.894095505 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "2023-04-06 20:28:03.894116704 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "2023-04-06 20:28:03.894134103 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "2023-04-06 20:28:03.894150902 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.1/attention/self/Reshape_output_0\n",
      "2023-04-06 20:28:03.894167801 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "2023-04-06 20:28:03.894188301 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /model/mobilebert/encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "2023-04-06 20:28:03.894194400 [I:onnxruntime:Default, reshape_fusion.cc:53 ApplyImpl] Total fused reshape node count: 8\n",
      "2023-04-06 20:28:03.895626539 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895636938 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895641538 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895645738 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895649938 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895654038 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895658238 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895664837 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895669137 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895673337 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895677237 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_251'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895681337 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895685336 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895689636 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_10_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895693536 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895698336 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895702736 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_234'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895706935 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_249'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895710935 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895714835 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_384'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895719735 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_417'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895724035 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_267'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895727935 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_232'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895732034 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_386'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895736134 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895740134 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895746034 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_265'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895750734 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895754633 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_295'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895758633 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_6_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895762633 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_297'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895766633 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895770633 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895775432 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_401'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895779632 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895783632 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895787532 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_419'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895791832 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_8_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895795832 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895799731 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_403'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895803831 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_446'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895807931 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_448'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895812131 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895816031 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895820131 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895825830 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/attention/self/Constant_9_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.895990123 [I:onnxruntime:Default, concat_slice_elimination.cc:36 ApplyImpl] Total fused concat node count: 0\n",
      "2023-04-06 20:28:03.897851643 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.897865743 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.0/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.897870843 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.897875642 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/embeddings/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.897879842 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.897885842 [I:onnxruntime:Default, graph.cc:3546 CleanUnusedInitializersAndNodeArgs] Removing initializer '/model/mobilebert/encoder/layer.1/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-04-06 20:28:03.899330480 [I:onnxruntime:Default, reshape_fusion.cc:53 ApplyImpl] Total fused reshape node count: 0\n",
      "2023-04-06 20:28:03.899424376 [I:onnxruntime:Default, concat_slice_elimination.cc:36 ApplyImpl] Total fused concat node count: 0\n",
      "2023-04-06 20:28:03.911185271 [I:onnxruntime:Default, gradient_graph_builder.cc:167 ReverseBFSWithStopGradient] Skip building gradient for input_1 of node: /model/SoftmaxCrossEntropyLoss\n",
      "2023-04-06 20:28:03.911213970 [I:onnxruntime:Default, gradient_graph_builder.cc:167 ReverseBFSWithStopGradient] Skip building gradient for input_1 of node: /model/mobilebert/embeddings/position_embeddings/Gather\n",
      "2023-04-06 20:28:03.911267568 [I:onnxruntime:Default, gradient_graph_builder.cc:176 ReverseBFSWithStopGradient] Skip building gradient for input_0 of node: /model/mobilebert/Castbecause element type is: 7\n",
      "2023-04-06 20:28:04.077986614 [W:onnxruntime:Default, checkpoint.cc:187 OrtSaveInternal] Checkpoint directory exists - data may be overwritten.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.training import artifacts\n",
    "import onnx\n",
    "\n",
    "requires_grad = []\n",
    "frozen_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        requires_grad.append(name)\n",
    "    else:\n",
    "        frozen_params.append(name)\n",
    "\n",
    "for name, param in model.named_buffers():\n",
    "    frozen_params.append(name)\n",
    "\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    model,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random input\n",
    "\n",
    "# expects\n",
    "# input_ids = torch.LongTensor of shape (batch size, seq len)\n",
    "# attention_mask = torch.FloatTensor of shape (batch size, seq len)\n",
    "# token_type_ids = torch.LongTensor of shape (bs, seq len)\n",
    "\n",
    "num_seq = 25\n",
    "seq_len = 150\n",
    "vocab = 20000\n",
    "input_ids = torch.randint(vocab, (num_seq, seq_len))\n",
    "attention_mask = torch.ones((num_seq, seq_len), dtype=torch.float)\n",
    "token_type_ids = torch.ones((num_seq, seq_len), dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, pad_to_len):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "    # filter out empty strings to remove unnecessary processing\n",
    "    examples[\"text\"] = [sent for sent in examples[\"text\"] if len(sent) > 0]\n",
    "    labels = tokenizer(examples[\"text\"], padding=\"max_length\", max_length=pad_to_len, truncation=True, return_tensors=\"pt\")\n",
    "    masked_examples = [mask(sent, pad_to_len) for sent in examples[\"text\"]]\n",
    "    inputs = tokenizer(masked_examples, padding=\"max_length\", max_length=pad_to_len, truncation=True, return_tensors=\"pt\")\n",
    "    labels = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id, labels[\"input_ids\"], -100)\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n",
    "\n",
    "def mask(sent, pad_to_len):\n",
    "    sent_words = sent.split()\n",
    "    mask_index = random.randint(0, min(len(sent_words), pad_to_len) - 1)\n",
    "    # replace random index with mask word, leaving punctuation as is\n",
    "    # ... this preprocessing means that the token masked might be the <unk> word\n",
    "    masked_words = [sent_words[ind] if ind != mask_index else re.sub(\"[a-zA-Z']+\", \"[MASK]\", sent_words[ind]) for ind in range(len(sent_words))]\n",
    "    return ' '.join(masked_words)\n",
    "\n",
    "def generate_tokens(corpus):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with a \"text\" feature.\n",
    "\n",
    "    Returns a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "    \"\"\"\n",
    "    # pad_to_len must be calculated before the batching happens to create consistent sizes in the resulting tensor\n",
    "    # pad_to_len = max([len(sent) for sent in corpus[\"text\"]])\n",
    "    pad_to_len = 80 # shortened for demonstration purposes\n",
    "    return corpus.map(tokenize_function, batched=True, fn_kwargs={\"pad_to_len\": pad_to_len})\n",
    "\n",
    "def generate_json_dict(token_dataset):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "\n",
    "    Basically changes the 2d Python lists into two fields: a shape & a flattened list, for easier conversion to OnnxValues\n",
    "\n",
    "    Returns a dictionary with the following keys: input_ids, input_size, token_type_ids, token_type_size, attention_mask, attention_mask_size, special_tokens_mask, special_tokens_size\n",
    "    \"\"\"\n",
    "    json_dict = {}\n",
    "    keys_to_convert = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    "\n",
    "    for key_name in keys_to_convert:\n",
    "        # add field for the shape of the tensor\n",
    "        json_dict[key_name + \"_shape\"] = [len(token_dataset[key_name]), len(token_dataset[key_name][0])]\n",
    "        # flatten list\n",
    "        json_dict[key_name] = [num for sent in token_dataset[key_name] for num in sent]\n",
    "    \n",
    "    return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset wikitext (/home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|| 3/3 [00:00<00:00, 693.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"wikitext\" \n",
    "dataset_config = \"wikitext-2-v1\"\n",
    "# corpus = type DatasetDict with three Datasets: test, train, validation\n",
    "corpus = load_dataset(dataset_name, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-332e266fc77aa9d5.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-acc30ce498b9f99c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-ceae3b1a41bfd1eb.arrow\n"
     ]
    }
   ],
   "source": [
    "test_tokens_dataset = generate_tokens(corpus[\"test\"])\n",
    "test_tokens = generate_json_dict(test_tokens_dataset)\n",
    "# corpus[\"train\"][\"text\"] = corpus[\"train\"][\"text\"][:5000]\n",
    "train_tokens_dataset = generate_tokens(corpus[\"train\"])\n",
    "train_tokens = generate_json_dict(train_tokens_dataset)\n",
    "validation_tokens_dataset = generate_tokens(corpus[\"validation\"])\n",
    "validation_tokens = generate_json_dict(validation_tokens_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all the tokens to a json file\n",
    "file_names = [\"test_tokens.json\", \"train_tokens.json\", \"validation_tokens.json\"]\n",
    "token_dicts = [test_tokens, train_tokens, validation_tokens]\n",
    "\n",
    "def write_dicts_to_files(file_names, dicts):\n",
    "    # assumes file_names and dicts are 2 lists w/ the same lengths\n",
    "    for i in range(len(file_names)):\n",
    "        with open(file_names[i], \"w\") as json_file:\n",
    "            json.dump(dicts[i], json_file)\n",
    "\n",
    "write_dicts_to_files(file_names, token_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime.training.api as orttraining\n",
    "import os\n",
    "\n",
    "checkpoint_state = orttraining.CheckpointState(\n",
    "    os.path.join(os.getcwd(), \"checkpoint\")\n",
    ")\n",
    "\n",
    "model = orttraining.Module(\n",
    "    os.path.join(os.getcwd(), \"training_model.onnx\"),\n",
    "    checkpoint_state,\n",
    "    os.path.join(os.getcwd(), \"eval_model.onnx\"),\n",
    ")\n",
    "\n",
    "optimizer = orttraining.Optimizer(\n",
    "    os.path.join(os.getcwd(), \"optimizer_model.onnx\"), model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids shape (10, 80)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "/bert_ort/carolinezhu/ort/onnxruntime/orttraining/orttraining/training_api/module.cc:438 onnxruntime::common::Status onnxruntime::training::api::Module::TrainStep(const std::vector<OrtValue>&, std::vector<OrtValue>&) [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: onnx::Reshape_3 for the following indices\n index: 0 Got: 10 Expected: 1\n index: 1 Got: 80 Expected: 9\n Please fix either the inputs or the model.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     avg_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m steps \n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m avg_loss\n\u001b[0;32m---> 55\u001b[0m api_train(model, test_tokens_dataset, optimizer, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m, in \u001b[0;36mapi_train\u001b[0;34m(model, inputs, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(inputs[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m][start_batch:end_batch])\n\u001b[1;32m     37\u001b[0m input_np_list \u001b[39m=\u001b[39m [input_ids, attention_mask, token_type_ids, labels]\n\u001b[0;32m---> 39\u001b[0m outputs \u001b[39m=\u001b[39m model(input_np_list)\n\u001b[1;32m     40\u001b[0m \u001b[39m# returns array of NaN of shape [item, 3d list]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/onnxruntime/training/api/module.py:55\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, user_inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m fetches \u001b[39m=\u001b[39m OrtValueVector()\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mtrain_step(forward_inputs, fetches)\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39meval_step(forward_inputs, fetches)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /bert_ort/carolinezhu/ort/onnxruntime/orttraining/orttraining/training_api/module.cc:438 onnxruntime::common::Status onnxruntime::training::api::Module::TrainStep(const std::vector<OrtValue>&, std::vector<OrtValue>&) [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: onnx::Reshape_3 for the following indices\n index: 0 Got: 10 Expected: 1\n index: 1 Got: 80 Expected: 9\n Please fix either the inputs or the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# this runs one epoch... w c# version, maybe run 2 epochs & linear learning rate scheduler\n",
    "# should be declared and used across the num of epochs... so maybe lr scheduler\n",
    "# can be passed in as an optional argument?\n",
    "def api_train(model, inputs, optimizer, batch_size):\n",
    "    \"\"\"\n",
    "    Does one epoch of training on CPU\n",
    "\n",
    "    Args:\n",
    "        model - ORTModule\n",
    "        inputs - Dictionary\n",
    "        optimizer - ORTTraining Optimizer\n",
    "        steps - int\n",
    "    \"\"\"\n",
    "    # loss reset and accumulated every epoch\n",
    "    total_loss = 0\n",
    "\n",
    "    model.lazy_reset_grad()\n",
    "    model.train()\n",
    "\n",
    "    size = len(inputs[\"input_ids\"])\n",
    "\n",
    "    steps = int(size / batch_size)\n",
    "    start_batch = 0\n",
    "    end_batch = start_batch + batch_size\n",
    "\n",
    "    for step in range(steps):\n",
    "        if start_batch >= size or end_batch >= size:\n",
    "            break\n",
    "        \n",
    "        # unpack and define inputs from inputs\n",
    "        input_ids = np.array(inputs[\"input_ids\"][start_batch:end_batch])\n",
    "        print(\"input ids shape\", input_ids.shape)\n",
    "        attention_mask = np.array(inputs[\"attention_mask\"][start_batch:end_batch])\n",
    "        token_type_ids = np.array(inputs[\"token_type_ids\"][start_batch:end_batch])\n",
    "        labels = np.array(inputs[\"labels\"][start_batch:end_batch])\n",
    "        input_np_list = [input_ids, attention_mask, token_type_ids, labels]\n",
    "\n",
    "        outputs = model(input_np_list)\n",
    "        # returns array of NaN of shape [item, 3d list]\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item() # .item() returns python value from the tensor\n",
    "        print(outputs)\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.get_contiguous_parameters(), 1.0) # prevent exploding gradients\n",
    "\n",
    "        optimizer.step() \n",
    "\n",
    "        start_batch += batch_size\n",
    "        end_batch = min(end_batch + batch_size, size)\n",
    "\n",
    "    avg_loss = total_loss / steps \n",
    "    return avg_loss\n",
    "\n",
    "api_train(model, test_tokens_dataset, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_tokens_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "\n",
    "session = InferenceSession(\"training_model.onnx\", providers=[\"CPUExecutionProvider\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
