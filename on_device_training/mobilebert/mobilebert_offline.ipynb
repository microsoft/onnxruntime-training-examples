{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import onnx\n",
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = transformers.AutoModel.from_pretrained('google/mobilebert-uncased')\n",
    "from transformers import MobileBertConfig, MobileBertModel \n",
    "config = MobileBertConfig(num_hidden_layers=4)\n",
    "model = MobileBertModel(config)\n",
    "model_name = 'mobilebert-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random input\n",
    "\n",
    "# expects\n",
    "# input_ids = torch.LongTensor of shape (batch size, seq len)\n",
    "# attention_mask = torch.FloatTensor of shape (batch size, seq len)\n",
    "# token_type_ids = torch.LongTensor of shape (bs, seq len)\n",
    "\n",
    "num_seq = 2\n",
    "seq_len = 150\n",
    "vocab = 20000\n",
    "input_ids = torch.randint(vocab, (num_seq, seq_len), requires_grad=False)\n",
    "attention_mask = torch.ones((num_seq, seq_len), dtype=torch.float, requires_grad=False)\n",
    "token_type_ids = torch.ones((num_seq, seq_len), dtype=torch.long, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(1000),\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:967: UserWarning: Warning: ONNX export of embedding with padding_idx >= 0 for training mode. ONNX does not support not updating the embedding vector at padding_idx during training.\n",
      "  warnings.warn(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, (input_ids, attention_mask, token_type_ids),\n",
    "                  f\"training_artifacts/{model_name}.onnx\", \n",
    "                  input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "                  output_names=[\"output\"],\n",
    "                   dynamic_axes={\n",
    "                     \"input_ids\": {0: \"num_seq\"},\n",
    "                     \"attention_mask\": {0: \"num_seq\"},\n",
    "                     \"token_type_ids\": {0: \"num_seq\"}\n",
    "                   },\n",
    "                   export_params=True, \n",
    "                   do_constant_folding=False,\n",
    "                   training=torch.onnx.TrainingMode.TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(1000),\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_seq = 1000\n",
    "seq_len = 150\n",
    "vocab = 20000\n",
    "input_ids = torch.randint(vocab, (num_seq, seq_len), requires_grad=False)\n",
    "attention_mask = torch.ones((num_seq, seq_len), dtype=torch.float, requires_grad=False)\n",
    "token_type_ids = torch.ones((num_seq, seq_len), dtype=torch.long, requires_grad=False)\n",
    "\n",
    "torch.onnx.export(model, (input_ids, attention_mask, token_type_ids),\n",
    "                  f\"training_artifacts/{model_name}.onnx\", \n",
    "                  input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "                  output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight True\n",
      "embeddings.position_embeddings.weight True\n",
      "embeddings.token_type_embeddings.weight True\n",
      "embeddings.embedding_transformation.weight True\n",
      "embeddings.embedding_transformation.bias True\n",
      "embeddings.LayerNorm.bias True\n",
      "embeddings.LayerNorm.weight True\n",
      "encoder.layer.0.attention.self.query.weight True\n",
      "encoder.layer.0.attention.self.query.bias True\n",
      "encoder.layer.0.attention.self.key.weight True\n",
      "encoder.layer.0.attention.self.key.bias True\n",
      "encoder.layer.0.attention.self.value.weight True\n",
      "encoder.layer.0.attention.self.value.bias True\n",
      "encoder.layer.0.attention.output.dense.weight True\n",
      "encoder.layer.0.attention.output.dense.bias True\n",
      "encoder.layer.0.attention.output.LayerNorm.bias True\n",
      "encoder.layer.0.attention.output.LayerNorm.weight True\n",
      "encoder.layer.0.intermediate.dense.weight True\n",
      "encoder.layer.0.intermediate.dense.bias True\n",
      "encoder.layer.0.output.dense.weight True\n",
      "encoder.layer.0.output.dense.bias True\n",
      "encoder.layer.0.output.LayerNorm.bias True\n",
      "encoder.layer.0.output.LayerNorm.weight True\n",
      "encoder.layer.0.output.bottleneck.dense.weight True\n",
      "encoder.layer.0.output.bottleneck.dense.bias True\n",
      "encoder.layer.0.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.0.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.0.bottleneck.input.dense.weight True\n",
      "encoder.layer.0.bottleneck.input.dense.bias True\n",
      "encoder.layer.0.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.0.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.0.bottleneck.attention.dense.weight True\n",
      "encoder.layer.0.bottleneck.attention.dense.bias True\n",
      "encoder.layer.0.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.0.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.0.output.dense.weight True\n",
      "encoder.layer.0.ffn.0.output.dense.bias True\n",
      "encoder.layer.0.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.1.output.dense.weight True\n",
      "encoder.layer.0.ffn.1.output.dense.bias True\n",
      "encoder.layer.0.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.2.output.dense.weight True\n",
      "encoder.layer.0.ffn.2.output.dense.bias True\n",
      "encoder.layer.0.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.1.attention.self.query.weight True\n",
      "encoder.layer.1.attention.self.query.bias True\n",
      "encoder.layer.1.attention.self.key.weight True\n",
      "encoder.layer.1.attention.self.key.bias True\n",
      "encoder.layer.1.attention.self.value.weight True\n",
      "encoder.layer.1.attention.self.value.bias True\n",
      "encoder.layer.1.attention.output.dense.weight True\n",
      "encoder.layer.1.attention.output.dense.bias True\n",
      "encoder.layer.1.attention.output.LayerNorm.bias True\n",
      "encoder.layer.1.attention.output.LayerNorm.weight True\n",
      "encoder.layer.1.intermediate.dense.weight True\n",
      "encoder.layer.1.intermediate.dense.bias True\n",
      "encoder.layer.1.output.dense.weight True\n",
      "encoder.layer.1.output.dense.bias True\n",
      "encoder.layer.1.output.LayerNorm.bias True\n",
      "encoder.layer.1.output.LayerNorm.weight True\n",
      "encoder.layer.1.output.bottleneck.dense.weight True\n",
      "encoder.layer.1.output.bottleneck.dense.bias True\n",
      "encoder.layer.1.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.1.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.1.bottleneck.input.dense.weight True\n",
      "encoder.layer.1.bottleneck.input.dense.bias True\n",
      "encoder.layer.1.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.1.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.1.bottleneck.attention.dense.weight True\n",
      "encoder.layer.1.bottleneck.attention.dense.bias True\n",
      "encoder.layer.1.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.1.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.0.output.dense.weight True\n",
      "encoder.layer.1.ffn.0.output.dense.bias True\n",
      "encoder.layer.1.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.1.output.dense.weight True\n",
      "encoder.layer.1.ffn.1.output.dense.bias True\n",
      "encoder.layer.1.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.2.output.dense.weight True\n",
      "encoder.layer.1.ffn.2.output.dense.bias True\n",
      "encoder.layer.1.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.2.attention.self.query.weight True\n",
      "encoder.layer.2.attention.self.query.bias True\n",
      "encoder.layer.2.attention.self.key.weight True\n",
      "encoder.layer.2.attention.self.key.bias True\n",
      "encoder.layer.2.attention.self.value.weight True\n",
      "encoder.layer.2.attention.self.value.bias True\n",
      "encoder.layer.2.attention.output.dense.weight True\n",
      "encoder.layer.2.attention.output.dense.bias True\n",
      "encoder.layer.2.attention.output.LayerNorm.bias True\n",
      "encoder.layer.2.attention.output.LayerNorm.weight True\n",
      "encoder.layer.2.intermediate.dense.weight True\n",
      "encoder.layer.2.intermediate.dense.bias True\n",
      "encoder.layer.2.output.dense.weight True\n",
      "encoder.layer.2.output.dense.bias True\n",
      "encoder.layer.2.output.LayerNorm.bias True\n",
      "encoder.layer.2.output.LayerNorm.weight True\n",
      "encoder.layer.2.output.bottleneck.dense.weight True\n",
      "encoder.layer.2.output.bottleneck.dense.bias True\n",
      "encoder.layer.2.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.2.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.2.bottleneck.input.dense.weight True\n",
      "encoder.layer.2.bottleneck.input.dense.bias True\n",
      "encoder.layer.2.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.2.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.2.bottleneck.attention.dense.weight True\n",
      "encoder.layer.2.bottleneck.attention.dense.bias True\n",
      "encoder.layer.2.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.2.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.0.output.dense.weight True\n",
      "encoder.layer.2.ffn.0.output.dense.bias True\n",
      "encoder.layer.2.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.1.output.dense.weight True\n",
      "encoder.layer.2.ffn.1.output.dense.bias True\n",
      "encoder.layer.2.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.2.output.dense.weight True\n",
      "encoder.layer.2.ffn.2.output.dense.bias True\n",
      "encoder.layer.2.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.3.attention.self.query.weight True\n",
      "encoder.layer.3.attention.self.query.bias True\n",
      "encoder.layer.3.attention.self.key.weight True\n",
      "encoder.layer.3.attention.self.key.bias True\n",
      "encoder.layer.3.attention.self.value.weight True\n",
      "encoder.layer.3.attention.self.value.bias True\n",
      "encoder.layer.3.attention.output.dense.weight True\n",
      "encoder.layer.3.attention.output.dense.bias True\n",
      "encoder.layer.3.attention.output.LayerNorm.bias True\n",
      "encoder.layer.3.attention.output.LayerNorm.weight True\n",
      "encoder.layer.3.intermediate.dense.weight True\n",
      "encoder.layer.3.intermediate.dense.bias True\n",
      "encoder.layer.3.output.dense.weight True\n",
      "encoder.layer.3.output.dense.bias True\n",
      "encoder.layer.3.output.LayerNorm.bias True\n",
      "encoder.layer.3.output.LayerNorm.weight True\n",
      "encoder.layer.3.output.bottleneck.dense.weight True\n",
      "encoder.layer.3.output.bottleneck.dense.bias True\n",
      "encoder.layer.3.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.3.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.3.bottleneck.input.dense.weight True\n",
      "encoder.layer.3.bottleneck.input.dense.bias True\n",
      "encoder.layer.3.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.3.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.3.bottleneck.attention.dense.weight True\n",
      "encoder.layer.3.bottleneck.attention.dense.bias True\n",
      "encoder.layer.3.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.3.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.0.output.dense.weight True\n",
      "encoder.layer.3.ffn.0.output.dense.bias True\n",
      "encoder.layer.3.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.1.output.dense.weight True\n",
      "encoder.layer.3.ffn.1.output.dense.bias True\n",
      "encoder.layer.3.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.2.output.dense.weight True\n",
      "encoder.layer.3.ffn.2.output.dense.bias True\n",
      "encoder.layer.3.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.4.attention.self.query.weight True\n",
      "encoder.layer.4.attention.self.query.bias True\n",
      "encoder.layer.4.attention.self.key.weight True\n",
      "encoder.layer.4.attention.self.key.bias True\n",
      "encoder.layer.4.attention.self.value.weight True\n",
      "encoder.layer.4.attention.self.value.bias True\n",
      "encoder.layer.4.attention.output.dense.weight True\n",
      "encoder.layer.4.attention.output.dense.bias True\n",
      "encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "encoder.layer.4.intermediate.dense.weight True\n",
      "encoder.layer.4.intermediate.dense.bias True\n",
      "encoder.layer.4.output.dense.weight True\n",
      "encoder.layer.4.output.dense.bias True\n",
      "encoder.layer.4.output.LayerNorm.bias True\n",
      "encoder.layer.4.output.LayerNorm.weight True\n",
      "encoder.layer.4.output.bottleneck.dense.weight True\n",
      "encoder.layer.4.output.bottleneck.dense.bias True\n",
      "encoder.layer.4.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.4.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.4.bottleneck.input.dense.weight True\n",
      "encoder.layer.4.bottleneck.input.dense.bias True\n",
      "encoder.layer.4.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.4.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.4.bottleneck.attention.dense.weight True\n",
      "encoder.layer.4.bottleneck.attention.dense.bias True\n",
      "encoder.layer.4.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.4.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.0.output.dense.weight True\n",
      "encoder.layer.4.ffn.0.output.dense.bias True\n",
      "encoder.layer.4.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.1.output.dense.weight True\n",
      "encoder.layer.4.ffn.1.output.dense.bias True\n",
      "encoder.layer.4.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.2.output.dense.weight True\n",
      "encoder.layer.4.ffn.2.output.dense.bias True\n",
      "encoder.layer.4.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.5.attention.self.query.weight True\n",
      "encoder.layer.5.attention.self.query.bias True\n",
      "encoder.layer.5.attention.self.key.weight True\n",
      "encoder.layer.5.attention.self.key.bias True\n",
      "encoder.layer.5.attention.self.value.weight True\n",
      "encoder.layer.5.attention.self.value.bias True\n",
      "encoder.layer.5.attention.output.dense.weight True\n",
      "encoder.layer.5.attention.output.dense.bias True\n",
      "encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "encoder.layer.5.intermediate.dense.weight True\n",
      "encoder.layer.5.intermediate.dense.bias True\n",
      "encoder.layer.5.output.dense.weight True\n",
      "encoder.layer.5.output.dense.bias True\n",
      "encoder.layer.5.output.LayerNorm.bias True\n",
      "encoder.layer.5.output.LayerNorm.weight True\n",
      "encoder.layer.5.output.bottleneck.dense.weight True\n",
      "encoder.layer.5.output.bottleneck.dense.bias True\n",
      "encoder.layer.5.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.5.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.5.bottleneck.input.dense.weight True\n",
      "encoder.layer.5.bottleneck.input.dense.bias True\n",
      "encoder.layer.5.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.5.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.5.bottleneck.attention.dense.weight True\n",
      "encoder.layer.5.bottleneck.attention.dense.bias True\n",
      "encoder.layer.5.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.5.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.0.output.dense.weight True\n",
      "encoder.layer.5.ffn.0.output.dense.bias True\n",
      "encoder.layer.5.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.1.output.dense.weight True\n",
      "encoder.layer.5.ffn.1.output.dense.bias True\n",
      "encoder.layer.5.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.2.output.dense.weight True\n",
      "encoder.layer.5.ffn.2.output.dense.bias True\n",
      "encoder.layer.5.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.6.attention.self.query.weight True\n",
      "encoder.layer.6.attention.self.query.bias True\n",
      "encoder.layer.6.attention.self.key.weight True\n",
      "encoder.layer.6.attention.self.key.bias True\n",
      "encoder.layer.6.attention.self.value.weight True\n",
      "encoder.layer.6.attention.self.value.bias True\n",
      "encoder.layer.6.attention.output.dense.weight True\n",
      "encoder.layer.6.attention.output.dense.bias True\n",
      "encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "encoder.layer.6.intermediate.dense.weight True\n",
      "encoder.layer.6.intermediate.dense.bias True\n",
      "encoder.layer.6.output.dense.weight True\n",
      "encoder.layer.6.output.dense.bias True\n",
      "encoder.layer.6.output.LayerNorm.bias True\n",
      "encoder.layer.6.output.LayerNorm.weight True\n",
      "encoder.layer.6.output.bottleneck.dense.weight True\n",
      "encoder.layer.6.output.bottleneck.dense.bias True\n",
      "encoder.layer.6.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.6.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.6.bottleneck.input.dense.weight True\n",
      "encoder.layer.6.bottleneck.input.dense.bias True\n",
      "encoder.layer.6.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.6.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.6.bottleneck.attention.dense.weight True\n",
      "encoder.layer.6.bottleneck.attention.dense.bias True\n",
      "encoder.layer.6.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.6.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.0.output.dense.weight True\n",
      "encoder.layer.6.ffn.0.output.dense.bias True\n",
      "encoder.layer.6.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.1.output.dense.weight True\n",
      "encoder.layer.6.ffn.1.output.dense.bias True\n",
      "encoder.layer.6.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.2.output.dense.weight True\n",
      "encoder.layer.6.ffn.2.output.dense.bias True\n",
      "encoder.layer.6.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.7.attention.self.query.weight True\n",
      "encoder.layer.7.attention.self.query.bias True\n",
      "encoder.layer.7.attention.self.key.weight True\n",
      "encoder.layer.7.attention.self.key.bias True\n",
      "encoder.layer.7.attention.self.value.weight True\n",
      "encoder.layer.7.attention.self.value.bias True\n",
      "encoder.layer.7.attention.output.dense.weight True\n",
      "encoder.layer.7.attention.output.dense.bias True\n",
      "encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "encoder.layer.7.intermediate.dense.weight True\n",
      "encoder.layer.7.intermediate.dense.bias True\n",
      "encoder.layer.7.output.dense.weight True\n",
      "encoder.layer.7.output.dense.bias True\n",
      "encoder.layer.7.output.LayerNorm.bias True\n",
      "encoder.layer.7.output.LayerNorm.weight True\n",
      "encoder.layer.7.output.bottleneck.dense.weight True\n",
      "encoder.layer.7.output.bottleneck.dense.bias True\n",
      "encoder.layer.7.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.7.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.7.bottleneck.input.dense.weight True\n",
      "encoder.layer.7.bottleneck.input.dense.bias True\n",
      "encoder.layer.7.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.7.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.7.bottleneck.attention.dense.weight True\n",
      "encoder.layer.7.bottleneck.attention.dense.bias True\n",
      "encoder.layer.7.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.7.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.0.output.dense.weight True\n",
      "encoder.layer.7.ffn.0.output.dense.bias True\n",
      "encoder.layer.7.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.1.output.dense.weight True\n",
      "encoder.layer.7.ffn.1.output.dense.bias True\n",
      "encoder.layer.7.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.2.output.dense.weight True\n",
      "encoder.layer.7.ffn.2.output.dense.bias True\n",
      "encoder.layer.7.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.8.attention.self.query.weight True\n",
      "encoder.layer.8.attention.self.query.bias True\n",
      "encoder.layer.8.attention.self.key.weight True\n",
      "encoder.layer.8.attention.self.key.bias True\n",
      "encoder.layer.8.attention.self.value.weight True\n",
      "encoder.layer.8.attention.self.value.bias True\n",
      "encoder.layer.8.attention.output.dense.weight True\n",
      "encoder.layer.8.attention.output.dense.bias True\n",
      "encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "encoder.layer.8.intermediate.dense.weight True\n",
      "encoder.layer.8.intermediate.dense.bias True\n",
      "encoder.layer.8.output.dense.weight True\n",
      "encoder.layer.8.output.dense.bias True\n",
      "encoder.layer.8.output.LayerNorm.bias True\n",
      "encoder.layer.8.output.LayerNorm.weight True\n",
      "encoder.layer.8.output.bottleneck.dense.weight True\n",
      "encoder.layer.8.output.bottleneck.dense.bias True\n",
      "encoder.layer.8.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.8.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.8.bottleneck.input.dense.weight True\n",
      "encoder.layer.8.bottleneck.input.dense.bias True\n",
      "encoder.layer.8.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.8.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.8.bottleneck.attention.dense.weight True\n",
      "encoder.layer.8.bottleneck.attention.dense.bias True\n",
      "encoder.layer.8.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.8.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.0.output.dense.weight True\n",
      "encoder.layer.8.ffn.0.output.dense.bias True\n",
      "encoder.layer.8.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.1.output.dense.weight True\n",
      "encoder.layer.8.ffn.1.output.dense.bias True\n",
      "encoder.layer.8.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.2.output.dense.weight True\n",
      "encoder.layer.8.ffn.2.output.dense.bias True\n",
      "encoder.layer.8.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.9.attention.self.query.weight True\n",
      "encoder.layer.9.attention.self.query.bias True\n",
      "encoder.layer.9.attention.self.key.weight True\n",
      "encoder.layer.9.attention.self.key.bias True\n",
      "encoder.layer.9.attention.self.value.weight True\n",
      "encoder.layer.9.attention.self.value.bias True\n",
      "encoder.layer.9.attention.output.dense.weight True\n",
      "encoder.layer.9.attention.output.dense.bias True\n",
      "encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "encoder.layer.9.intermediate.dense.weight True\n",
      "encoder.layer.9.intermediate.dense.bias True\n",
      "encoder.layer.9.output.dense.weight True\n",
      "encoder.layer.9.output.dense.bias True\n",
      "encoder.layer.9.output.LayerNorm.bias True\n",
      "encoder.layer.9.output.LayerNorm.weight True\n",
      "encoder.layer.9.output.bottleneck.dense.weight True\n",
      "encoder.layer.9.output.bottleneck.dense.bias True\n",
      "encoder.layer.9.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.9.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.9.bottleneck.input.dense.weight True\n",
      "encoder.layer.9.bottleneck.input.dense.bias True\n",
      "encoder.layer.9.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.9.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.9.bottleneck.attention.dense.weight True\n",
      "encoder.layer.9.bottleneck.attention.dense.bias True\n",
      "encoder.layer.9.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.9.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.0.output.dense.weight True\n",
      "encoder.layer.9.ffn.0.output.dense.bias True\n",
      "encoder.layer.9.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.1.output.dense.weight True\n",
      "encoder.layer.9.ffn.1.output.dense.bias True\n",
      "encoder.layer.9.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.2.output.dense.weight True\n",
      "encoder.layer.9.ffn.2.output.dense.bias True\n",
      "encoder.layer.9.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.10.attention.self.query.weight True\n",
      "encoder.layer.10.attention.self.query.bias True\n",
      "encoder.layer.10.attention.self.key.weight True\n",
      "encoder.layer.10.attention.self.key.bias True\n",
      "encoder.layer.10.attention.self.value.weight True\n",
      "encoder.layer.10.attention.self.value.bias True\n",
      "encoder.layer.10.attention.output.dense.weight True\n",
      "encoder.layer.10.attention.output.dense.bias True\n",
      "encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "encoder.layer.10.intermediate.dense.weight True\n",
      "encoder.layer.10.intermediate.dense.bias True\n",
      "encoder.layer.10.output.dense.weight True\n",
      "encoder.layer.10.output.dense.bias True\n",
      "encoder.layer.10.output.LayerNorm.bias True\n",
      "encoder.layer.10.output.LayerNorm.weight True\n",
      "encoder.layer.10.output.bottleneck.dense.weight True\n",
      "encoder.layer.10.output.bottleneck.dense.bias True\n",
      "encoder.layer.10.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.10.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.10.bottleneck.input.dense.weight True\n",
      "encoder.layer.10.bottleneck.input.dense.bias True\n",
      "encoder.layer.10.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.10.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.10.bottleneck.attention.dense.weight True\n",
      "encoder.layer.10.bottleneck.attention.dense.bias True\n",
      "encoder.layer.10.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.10.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.0.output.dense.weight True\n",
      "encoder.layer.10.ffn.0.output.dense.bias True\n",
      "encoder.layer.10.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.1.output.dense.weight True\n",
      "encoder.layer.10.ffn.1.output.dense.bias True\n",
      "encoder.layer.10.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.2.output.dense.weight True\n",
      "encoder.layer.10.ffn.2.output.dense.bias True\n",
      "encoder.layer.10.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.11.attention.self.query.weight True\n",
      "encoder.layer.11.attention.self.query.bias True\n",
      "encoder.layer.11.attention.self.key.weight True\n",
      "encoder.layer.11.attention.self.key.bias True\n",
      "encoder.layer.11.attention.self.value.weight True\n",
      "encoder.layer.11.attention.self.value.bias True\n",
      "encoder.layer.11.attention.output.dense.weight True\n",
      "encoder.layer.11.attention.output.dense.bias True\n",
      "encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "encoder.layer.11.intermediate.dense.weight True\n",
      "encoder.layer.11.intermediate.dense.bias True\n",
      "encoder.layer.11.output.dense.weight True\n",
      "encoder.layer.11.output.dense.bias True\n",
      "encoder.layer.11.output.LayerNorm.bias True\n",
      "encoder.layer.11.output.LayerNorm.weight True\n",
      "encoder.layer.11.output.bottleneck.dense.weight True\n",
      "encoder.layer.11.output.bottleneck.dense.bias True\n",
      "encoder.layer.11.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.11.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.11.bottleneck.input.dense.weight True\n",
      "encoder.layer.11.bottleneck.input.dense.bias True\n",
      "encoder.layer.11.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.11.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.11.bottleneck.attention.dense.weight True\n",
      "encoder.layer.11.bottleneck.attention.dense.bias True\n",
      "encoder.layer.11.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.11.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.0.output.dense.weight True\n",
      "encoder.layer.11.ffn.0.output.dense.bias True\n",
      "encoder.layer.11.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.1.output.dense.weight True\n",
      "encoder.layer.11.ffn.1.output.dense.bias True\n",
      "encoder.layer.11.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.2.output.dense.weight True\n",
      "encoder.layer.11.ffn.2.output.dense.bias True\n",
      "encoder.layer.11.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.12.attention.self.query.weight True\n",
      "encoder.layer.12.attention.self.query.bias True\n",
      "encoder.layer.12.attention.self.key.weight True\n",
      "encoder.layer.12.attention.self.key.bias True\n",
      "encoder.layer.12.attention.self.value.weight True\n",
      "encoder.layer.12.attention.self.value.bias True\n",
      "encoder.layer.12.attention.output.dense.weight True\n",
      "encoder.layer.12.attention.output.dense.bias True\n",
      "encoder.layer.12.attention.output.LayerNorm.bias True\n",
      "encoder.layer.12.attention.output.LayerNorm.weight True\n",
      "encoder.layer.12.intermediate.dense.weight True\n",
      "encoder.layer.12.intermediate.dense.bias True\n",
      "encoder.layer.12.output.dense.weight True\n",
      "encoder.layer.12.output.dense.bias True\n",
      "encoder.layer.12.output.LayerNorm.bias True\n",
      "encoder.layer.12.output.LayerNorm.weight True\n",
      "encoder.layer.12.output.bottleneck.dense.weight True\n",
      "encoder.layer.12.output.bottleneck.dense.bias True\n",
      "encoder.layer.12.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.12.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.12.bottleneck.input.dense.weight True\n",
      "encoder.layer.12.bottleneck.input.dense.bias True\n",
      "encoder.layer.12.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.12.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.12.bottleneck.attention.dense.weight True\n",
      "encoder.layer.12.bottleneck.attention.dense.bias True\n",
      "encoder.layer.12.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.12.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.0.output.dense.weight True\n",
      "encoder.layer.12.ffn.0.output.dense.bias True\n",
      "encoder.layer.12.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.1.output.dense.weight True\n",
      "encoder.layer.12.ffn.1.output.dense.bias True\n",
      "encoder.layer.12.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.2.output.dense.weight True\n",
      "encoder.layer.12.ffn.2.output.dense.bias True\n",
      "encoder.layer.12.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.13.attention.self.query.weight True\n",
      "encoder.layer.13.attention.self.query.bias True\n",
      "encoder.layer.13.attention.self.key.weight True\n",
      "encoder.layer.13.attention.self.key.bias True\n",
      "encoder.layer.13.attention.self.value.weight True\n",
      "encoder.layer.13.attention.self.value.bias True\n",
      "encoder.layer.13.attention.output.dense.weight True\n",
      "encoder.layer.13.attention.output.dense.bias True\n",
      "encoder.layer.13.attention.output.LayerNorm.bias True\n",
      "encoder.layer.13.attention.output.LayerNorm.weight True\n",
      "encoder.layer.13.intermediate.dense.weight True\n",
      "encoder.layer.13.intermediate.dense.bias True\n",
      "encoder.layer.13.output.dense.weight True\n",
      "encoder.layer.13.output.dense.bias True\n",
      "encoder.layer.13.output.LayerNorm.bias True\n",
      "encoder.layer.13.output.LayerNorm.weight True\n",
      "encoder.layer.13.output.bottleneck.dense.weight True\n",
      "encoder.layer.13.output.bottleneck.dense.bias True\n",
      "encoder.layer.13.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.13.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.13.bottleneck.input.dense.weight True\n",
      "encoder.layer.13.bottleneck.input.dense.bias True\n",
      "encoder.layer.13.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.13.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.13.bottleneck.attention.dense.weight True\n",
      "encoder.layer.13.bottleneck.attention.dense.bias True\n",
      "encoder.layer.13.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.13.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.0.output.dense.weight True\n",
      "encoder.layer.13.ffn.0.output.dense.bias True\n",
      "encoder.layer.13.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.1.output.dense.weight True\n",
      "encoder.layer.13.ffn.1.output.dense.bias True\n",
      "encoder.layer.13.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.2.output.dense.weight True\n",
      "encoder.layer.13.ffn.2.output.dense.bias True\n",
      "encoder.layer.13.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.14.attention.self.query.weight True\n",
      "encoder.layer.14.attention.self.query.bias True\n",
      "encoder.layer.14.attention.self.key.weight True\n",
      "encoder.layer.14.attention.self.key.bias True\n",
      "encoder.layer.14.attention.self.value.weight True\n",
      "encoder.layer.14.attention.self.value.bias True\n",
      "encoder.layer.14.attention.output.dense.weight True\n",
      "encoder.layer.14.attention.output.dense.bias True\n",
      "encoder.layer.14.attention.output.LayerNorm.bias True\n",
      "encoder.layer.14.attention.output.LayerNorm.weight True\n",
      "encoder.layer.14.intermediate.dense.weight True\n",
      "encoder.layer.14.intermediate.dense.bias True\n",
      "encoder.layer.14.output.dense.weight True\n",
      "encoder.layer.14.output.dense.bias True\n",
      "encoder.layer.14.output.LayerNorm.bias True\n",
      "encoder.layer.14.output.LayerNorm.weight True\n",
      "encoder.layer.14.output.bottleneck.dense.weight True\n",
      "encoder.layer.14.output.bottleneck.dense.bias True\n",
      "encoder.layer.14.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.14.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.14.bottleneck.input.dense.weight True\n",
      "encoder.layer.14.bottleneck.input.dense.bias True\n",
      "encoder.layer.14.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.14.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.14.bottleneck.attention.dense.weight True\n",
      "encoder.layer.14.bottleneck.attention.dense.bias True\n",
      "encoder.layer.14.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.14.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.0.output.dense.weight True\n",
      "encoder.layer.14.ffn.0.output.dense.bias True\n",
      "encoder.layer.14.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.1.output.dense.weight True\n",
      "encoder.layer.14.ffn.1.output.dense.bias True\n",
      "encoder.layer.14.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.2.output.dense.weight True\n",
      "encoder.layer.14.ffn.2.output.dense.bias True\n",
      "encoder.layer.14.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.15.attention.self.query.weight True\n",
      "encoder.layer.15.attention.self.query.bias True\n",
      "encoder.layer.15.attention.self.key.weight True\n",
      "encoder.layer.15.attention.self.key.bias True\n",
      "encoder.layer.15.attention.self.value.weight True\n",
      "encoder.layer.15.attention.self.value.bias True\n",
      "encoder.layer.15.attention.output.dense.weight True\n",
      "encoder.layer.15.attention.output.dense.bias True\n",
      "encoder.layer.15.attention.output.LayerNorm.bias True\n",
      "encoder.layer.15.attention.output.LayerNorm.weight True\n",
      "encoder.layer.15.intermediate.dense.weight True\n",
      "encoder.layer.15.intermediate.dense.bias True\n",
      "encoder.layer.15.output.dense.weight True\n",
      "encoder.layer.15.output.dense.bias True\n",
      "encoder.layer.15.output.LayerNorm.bias True\n",
      "encoder.layer.15.output.LayerNorm.weight True\n",
      "encoder.layer.15.output.bottleneck.dense.weight True\n",
      "encoder.layer.15.output.bottleneck.dense.bias True\n",
      "encoder.layer.15.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.15.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.15.bottleneck.input.dense.weight True\n",
      "encoder.layer.15.bottleneck.input.dense.bias True\n",
      "encoder.layer.15.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.15.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.15.bottleneck.attention.dense.weight True\n",
      "encoder.layer.15.bottleneck.attention.dense.bias True\n",
      "encoder.layer.15.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.15.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.0.output.dense.weight True\n",
      "encoder.layer.15.ffn.0.output.dense.bias True\n",
      "encoder.layer.15.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.1.output.dense.weight True\n",
      "encoder.layer.15.ffn.1.output.dense.bias True\n",
      "encoder.layer.15.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.2.output.dense.weight True\n",
      "encoder.layer.15.ffn.2.output.dense.bias True\n",
      "encoder.layer.15.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.16.attention.self.query.weight True\n",
      "encoder.layer.16.attention.self.query.bias True\n",
      "encoder.layer.16.attention.self.key.weight True\n",
      "encoder.layer.16.attention.self.key.bias True\n",
      "encoder.layer.16.attention.self.value.weight True\n",
      "encoder.layer.16.attention.self.value.bias True\n",
      "encoder.layer.16.attention.output.dense.weight True\n",
      "encoder.layer.16.attention.output.dense.bias True\n",
      "encoder.layer.16.attention.output.LayerNorm.bias True\n",
      "encoder.layer.16.attention.output.LayerNorm.weight True\n",
      "encoder.layer.16.intermediate.dense.weight True\n",
      "encoder.layer.16.intermediate.dense.bias True\n",
      "encoder.layer.16.output.dense.weight True\n",
      "encoder.layer.16.output.dense.bias True\n",
      "encoder.layer.16.output.LayerNorm.bias True\n",
      "encoder.layer.16.output.LayerNorm.weight True\n",
      "encoder.layer.16.output.bottleneck.dense.weight True\n",
      "encoder.layer.16.output.bottleneck.dense.bias True\n",
      "encoder.layer.16.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.16.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.16.bottleneck.input.dense.weight True\n",
      "encoder.layer.16.bottleneck.input.dense.bias True\n",
      "encoder.layer.16.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.16.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.16.bottleneck.attention.dense.weight True\n",
      "encoder.layer.16.bottleneck.attention.dense.bias True\n",
      "encoder.layer.16.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.16.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.0.output.dense.weight True\n",
      "encoder.layer.16.ffn.0.output.dense.bias True\n",
      "encoder.layer.16.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.1.output.dense.weight True\n",
      "encoder.layer.16.ffn.1.output.dense.bias True\n",
      "encoder.layer.16.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.2.output.dense.weight True\n",
      "encoder.layer.16.ffn.2.output.dense.bias True\n",
      "encoder.layer.16.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.17.attention.self.query.weight True\n",
      "encoder.layer.17.attention.self.query.bias True\n",
      "encoder.layer.17.attention.self.key.weight True\n",
      "encoder.layer.17.attention.self.key.bias True\n",
      "encoder.layer.17.attention.self.value.weight True\n",
      "encoder.layer.17.attention.self.value.bias True\n",
      "encoder.layer.17.attention.output.dense.weight True\n",
      "encoder.layer.17.attention.output.dense.bias True\n",
      "encoder.layer.17.attention.output.LayerNorm.bias True\n",
      "encoder.layer.17.attention.output.LayerNorm.weight True\n",
      "encoder.layer.17.intermediate.dense.weight True\n",
      "encoder.layer.17.intermediate.dense.bias True\n",
      "encoder.layer.17.output.dense.weight True\n",
      "encoder.layer.17.output.dense.bias True\n",
      "encoder.layer.17.output.LayerNorm.bias True\n",
      "encoder.layer.17.output.LayerNorm.weight True\n",
      "encoder.layer.17.output.bottleneck.dense.weight True\n",
      "encoder.layer.17.output.bottleneck.dense.bias True\n",
      "encoder.layer.17.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.17.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.17.bottleneck.input.dense.weight True\n",
      "encoder.layer.17.bottleneck.input.dense.bias True\n",
      "encoder.layer.17.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.17.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.17.bottleneck.attention.dense.weight True\n",
      "encoder.layer.17.bottleneck.attention.dense.bias True\n",
      "encoder.layer.17.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.17.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.0.output.dense.weight True\n",
      "encoder.layer.17.ffn.0.output.dense.bias True\n",
      "encoder.layer.17.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.1.output.dense.weight True\n",
      "encoder.layer.17.ffn.1.output.dense.bias True\n",
      "encoder.layer.17.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.2.output.dense.weight True\n",
      "encoder.layer.17.ffn.2.output.dense.bias True\n",
      "encoder.layer.17.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.18.attention.self.query.weight True\n",
      "encoder.layer.18.attention.self.query.bias True\n",
      "encoder.layer.18.attention.self.key.weight True\n",
      "encoder.layer.18.attention.self.key.bias True\n",
      "encoder.layer.18.attention.self.value.weight True\n",
      "encoder.layer.18.attention.self.value.bias True\n",
      "encoder.layer.18.attention.output.dense.weight True\n",
      "encoder.layer.18.attention.output.dense.bias True\n",
      "encoder.layer.18.attention.output.LayerNorm.bias True\n",
      "encoder.layer.18.attention.output.LayerNorm.weight True\n",
      "encoder.layer.18.intermediate.dense.weight True\n",
      "encoder.layer.18.intermediate.dense.bias True\n",
      "encoder.layer.18.output.dense.weight True\n",
      "encoder.layer.18.output.dense.bias True\n",
      "encoder.layer.18.output.LayerNorm.bias True\n",
      "encoder.layer.18.output.LayerNorm.weight True\n",
      "encoder.layer.18.output.bottleneck.dense.weight True\n",
      "encoder.layer.18.output.bottleneck.dense.bias True\n",
      "encoder.layer.18.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.18.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.18.bottleneck.input.dense.weight True\n",
      "encoder.layer.18.bottleneck.input.dense.bias True\n",
      "encoder.layer.18.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.18.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.18.bottleneck.attention.dense.weight True\n",
      "encoder.layer.18.bottleneck.attention.dense.bias True\n",
      "encoder.layer.18.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.18.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.0.output.dense.weight True\n",
      "encoder.layer.18.ffn.0.output.dense.bias True\n",
      "encoder.layer.18.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.1.output.dense.weight True\n",
      "encoder.layer.18.ffn.1.output.dense.bias True\n",
      "encoder.layer.18.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.2.output.dense.weight True\n",
      "encoder.layer.18.ffn.2.output.dense.bias True\n",
      "encoder.layer.18.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.19.attention.self.query.weight True\n",
      "encoder.layer.19.attention.self.query.bias True\n",
      "encoder.layer.19.attention.self.key.weight True\n",
      "encoder.layer.19.attention.self.key.bias True\n",
      "encoder.layer.19.attention.self.value.weight True\n",
      "encoder.layer.19.attention.self.value.bias True\n",
      "encoder.layer.19.attention.output.dense.weight True\n",
      "encoder.layer.19.attention.output.dense.bias True\n",
      "encoder.layer.19.attention.output.LayerNorm.bias True\n",
      "encoder.layer.19.attention.output.LayerNorm.weight True\n",
      "encoder.layer.19.intermediate.dense.weight True\n",
      "encoder.layer.19.intermediate.dense.bias True\n",
      "encoder.layer.19.output.dense.weight True\n",
      "encoder.layer.19.output.dense.bias True\n",
      "encoder.layer.19.output.LayerNorm.bias True\n",
      "encoder.layer.19.output.LayerNorm.weight True\n",
      "encoder.layer.19.output.bottleneck.dense.weight True\n",
      "encoder.layer.19.output.bottleneck.dense.bias True\n",
      "encoder.layer.19.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.19.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.19.bottleneck.input.dense.weight True\n",
      "encoder.layer.19.bottleneck.input.dense.bias True\n",
      "encoder.layer.19.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.19.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.19.bottleneck.attention.dense.weight True\n",
      "encoder.layer.19.bottleneck.attention.dense.bias True\n",
      "encoder.layer.19.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.19.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.0.output.dense.weight True\n",
      "encoder.layer.19.ffn.0.output.dense.bias True\n",
      "encoder.layer.19.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.1.output.dense.weight True\n",
      "encoder.layer.19.ffn.1.output.dense.bias True\n",
      "encoder.layer.19.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.2.output.dense.weight True\n",
      "encoder.layer.19.ffn.2.output.dense.bias True\n",
      "encoder.layer.19.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.20.attention.self.query.weight True\n",
      "encoder.layer.20.attention.self.query.bias True\n",
      "encoder.layer.20.attention.self.key.weight True\n",
      "encoder.layer.20.attention.self.key.bias True\n",
      "encoder.layer.20.attention.self.value.weight True\n",
      "encoder.layer.20.attention.self.value.bias True\n",
      "encoder.layer.20.attention.output.dense.weight True\n",
      "encoder.layer.20.attention.output.dense.bias True\n",
      "encoder.layer.20.attention.output.LayerNorm.bias True\n",
      "encoder.layer.20.attention.output.LayerNorm.weight True\n",
      "encoder.layer.20.intermediate.dense.weight True\n",
      "encoder.layer.20.intermediate.dense.bias True\n",
      "encoder.layer.20.output.dense.weight True\n",
      "encoder.layer.20.output.dense.bias True\n",
      "encoder.layer.20.output.LayerNorm.bias True\n",
      "encoder.layer.20.output.LayerNorm.weight True\n",
      "encoder.layer.20.output.bottleneck.dense.weight True\n",
      "encoder.layer.20.output.bottleneck.dense.bias True\n",
      "encoder.layer.20.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.20.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.20.bottleneck.input.dense.weight True\n",
      "encoder.layer.20.bottleneck.input.dense.bias True\n",
      "encoder.layer.20.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.20.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.20.bottleneck.attention.dense.weight True\n",
      "encoder.layer.20.bottleneck.attention.dense.bias True\n",
      "encoder.layer.20.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.20.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.0.output.dense.weight True\n",
      "encoder.layer.20.ffn.0.output.dense.bias True\n",
      "encoder.layer.20.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.1.output.dense.weight True\n",
      "encoder.layer.20.ffn.1.output.dense.bias True\n",
      "encoder.layer.20.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.2.output.dense.weight True\n",
      "encoder.layer.20.ffn.2.output.dense.bias True\n",
      "encoder.layer.20.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.21.attention.self.query.weight True\n",
      "encoder.layer.21.attention.self.query.bias True\n",
      "encoder.layer.21.attention.self.key.weight True\n",
      "encoder.layer.21.attention.self.key.bias True\n",
      "encoder.layer.21.attention.self.value.weight True\n",
      "encoder.layer.21.attention.self.value.bias True\n",
      "encoder.layer.21.attention.output.dense.weight True\n",
      "encoder.layer.21.attention.output.dense.bias True\n",
      "encoder.layer.21.attention.output.LayerNorm.bias True\n",
      "encoder.layer.21.attention.output.LayerNorm.weight True\n",
      "encoder.layer.21.intermediate.dense.weight True\n",
      "encoder.layer.21.intermediate.dense.bias True\n",
      "encoder.layer.21.output.dense.weight True\n",
      "encoder.layer.21.output.dense.bias True\n",
      "encoder.layer.21.output.LayerNorm.bias True\n",
      "encoder.layer.21.output.LayerNorm.weight True\n",
      "encoder.layer.21.output.bottleneck.dense.weight True\n",
      "encoder.layer.21.output.bottleneck.dense.bias True\n",
      "encoder.layer.21.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.21.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.21.bottleneck.input.dense.weight True\n",
      "encoder.layer.21.bottleneck.input.dense.bias True\n",
      "encoder.layer.21.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.21.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.21.bottleneck.attention.dense.weight True\n",
      "encoder.layer.21.bottleneck.attention.dense.bias True\n",
      "encoder.layer.21.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.21.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.0.output.dense.weight True\n",
      "encoder.layer.21.ffn.0.output.dense.bias True\n",
      "encoder.layer.21.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.1.output.dense.weight True\n",
      "encoder.layer.21.ffn.1.output.dense.bias True\n",
      "encoder.layer.21.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.2.output.dense.weight True\n",
      "encoder.layer.21.ffn.2.output.dense.bias True\n",
      "encoder.layer.21.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.22.attention.self.query.weight True\n",
      "encoder.layer.22.attention.self.query.bias True\n",
      "encoder.layer.22.attention.self.key.weight True\n",
      "encoder.layer.22.attention.self.key.bias True\n",
      "encoder.layer.22.attention.self.value.weight True\n",
      "encoder.layer.22.attention.self.value.bias True\n",
      "encoder.layer.22.attention.output.dense.weight True\n",
      "encoder.layer.22.attention.output.dense.bias True\n",
      "encoder.layer.22.attention.output.LayerNorm.bias True\n",
      "encoder.layer.22.attention.output.LayerNorm.weight True\n",
      "encoder.layer.22.intermediate.dense.weight True\n",
      "encoder.layer.22.intermediate.dense.bias True\n",
      "encoder.layer.22.output.dense.weight True\n",
      "encoder.layer.22.output.dense.bias True\n",
      "encoder.layer.22.output.LayerNorm.bias True\n",
      "encoder.layer.22.output.LayerNorm.weight True\n",
      "encoder.layer.22.output.bottleneck.dense.weight True\n",
      "encoder.layer.22.output.bottleneck.dense.bias True\n",
      "encoder.layer.22.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.22.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.22.bottleneck.input.dense.weight True\n",
      "encoder.layer.22.bottleneck.input.dense.bias True\n",
      "encoder.layer.22.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.22.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.22.bottleneck.attention.dense.weight True\n",
      "encoder.layer.22.bottleneck.attention.dense.bias True\n",
      "encoder.layer.22.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.22.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.0.output.dense.weight True\n",
      "encoder.layer.22.ffn.0.output.dense.bias True\n",
      "encoder.layer.22.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.1.output.dense.weight True\n",
      "encoder.layer.22.ffn.1.output.dense.bias True\n",
      "encoder.layer.22.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.2.output.dense.weight True\n",
      "encoder.layer.22.ffn.2.output.dense.bias True\n",
      "encoder.layer.22.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.23.attention.self.query.weight True\n",
      "encoder.layer.23.attention.self.query.bias True\n",
      "encoder.layer.23.attention.self.key.weight True\n",
      "encoder.layer.23.attention.self.key.bias True\n",
      "encoder.layer.23.attention.self.value.weight True\n",
      "encoder.layer.23.attention.self.value.bias True\n",
      "encoder.layer.23.attention.output.dense.weight True\n",
      "encoder.layer.23.attention.output.dense.bias True\n",
      "encoder.layer.23.attention.output.LayerNorm.bias True\n",
      "encoder.layer.23.attention.output.LayerNorm.weight True\n",
      "encoder.layer.23.intermediate.dense.weight True\n",
      "encoder.layer.23.intermediate.dense.bias True\n",
      "encoder.layer.23.output.dense.weight True\n",
      "encoder.layer.23.output.dense.bias True\n",
      "encoder.layer.23.output.LayerNorm.bias True\n",
      "encoder.layer.23.output.LayerNorm.weight True\n",
      "encoder.layer.23.output.bottleneck.dense.weight True\n",
      "encoder.layer.23.output.bottleneck.dense.bias True\n",
      "encoder.layer.23.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.23.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.23.bottleneck.input.dense.weight True\n",
      "encoder.layer.23.bottleneck.input.dense.bias True\n",
      "encoder.layer.23.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.23.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.23.bottleneck.attention.dense.weight True\n",
      "encoder.layer.23.bottleneck.attention.dense.bias True\n",
      "encoder.layer.23.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.23.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.0.output.dense.weight True\n",
      "encoder.layer.23.ffn.0.output.dense.bias True\n",
      "encoder.layer.23.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.1.output.dense.weight True\n",
      "encoder.layer.23.ffn.1.output.dense.bias True\n",
      "encoder.layer.23.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.2.output.dense.weight True\n",
      "encoder.layer.23.ffn.2.output.dense.bias True\n",
      "encoder.layer.23.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.2.output.LayerNorm.weight True\n",
      "embeddings.position_ids\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "for name, buffer in model.named_buffers():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading onnx model\n",
      "done creating trainingblock\n",
      "within \"with\" block\n",
      "inside mobilebertwithloss build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 16:28:45.468425642 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Cast_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468469340 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Sub_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468494639 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Gather_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468499139 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Mul_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468503339 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Transpose_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468507439 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Reshape_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468511539 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Cast_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468521138 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/ConstantOfShape_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468528438 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Sub_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468537037 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Shape_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468541537 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Mul_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468548537 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Gather_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468553937 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Reshape_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468561536 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_794'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468566536 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Concat_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468572636 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_779'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468577136 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Reshape_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468581336 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468585435 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Shape_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468589935 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Concat_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468594135 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_325'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468598335 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Shape_254'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468602235 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_25_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468608534 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_356'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468612634 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Slice_4_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468616634 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468621134 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_340'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468625334 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468629933 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468633833 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468637833 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_12_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468642833 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_537'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468646833 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_26_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468651733 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/ConstantOfShape_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468657632 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Transpose_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468661632 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Shape_225'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468665832 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_796'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468669732 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_9_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468673832 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_30_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468677831 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_13_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468682031 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_358'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468685831 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_29_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468690031 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_342'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468695231 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_31_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468700130 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_15_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468704030 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468709030 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_323'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468714530 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_810'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468718830 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_16_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468722929 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_659'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468727129 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468731429 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_386'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468736229 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_777'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468741329 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_688'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468745528 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_27_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468749428 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_475'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468753528 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Slice_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468757628 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468761628 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_477'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468766028 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_839'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468770227 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_494'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468774627 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_14_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468778627 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_17_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468783327 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_508'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468787327 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_28_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468792526 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_643'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468796626 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_510'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468800626 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_24_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468804826 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Reshape_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468809326 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_812'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468814026 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_626'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468817925 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_628'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468822525 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_645'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468826425 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_661'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468830425 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/Constant_23_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.468835225 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_492'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.469209208 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "2023-03-30 16:28:45.469235307 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.0/attention/self/Reshape_output_0\n",
      "2023-03-30 16:28:45.469256406 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "2023-03-30 16:28:45.469281205 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "2023-03-30 16:28:45.469321104 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "2023-03-30 16:28:45.469343703 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.1/attention/self/Reshape_output_0\n",
      "2023-03-30 16:28:45.469364402 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "2023-03-30 16:28:45.469388301 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "2023-03-30 16:28:45.469410600 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.2/attention/self/Reshape_1_output_0\n",
      "2023-03-30 16:28:45.469430799 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.2/attention/self/Reshape_output_0\n",
      "2023-03-30 16:28:45.469451498 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.2/attention/self/Reshape_2_output_0\n",
      "2023-03-30 16:28:45.469476097 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.2/attention/self/Reshape_3_output_0\n",
      "2023-03-30 16:28:45.469500496 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.3/attention/self/Reshape_1_output_0\n",
      "2023-03-30 16:28:45.469520595 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.3/attention/self/Reshape_output_0\n",
      "2023-03-30 16:28:45.469540794 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.3/attention/self/Reshape_2_output_0\n",
      "2023-03-30 16:28:45.469565093 [I:onnxruntime:Default, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /encoder/layer.3/attention/self/Reshape_3_output_0\n",
      "2023-03-30 16:28:45.469571793 [I:onnxruntime:Default, reshape_fusion.cc:53 ApplyImpl] Total fused reshape node count: 16\n",
      "2023-03-30 16:28:45.471875493 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471886193 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471890993 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471895192 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471899292 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471903492 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471907892 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471911792 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471915792 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471919791 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471923691 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471927591 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471931591 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471935391 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471939490 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471945290 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471949290 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_6_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471953390 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_14_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471957790 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_837'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471961990 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_835'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471965989 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_8_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471969789 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471973989 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471977989 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_808'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471981889 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471985888 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471989688 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471993788 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_792'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.471997688 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_773'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472001688 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472005688 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472009887 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472013787 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472017887 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_6_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472022987 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_336'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472026987 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_321'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472030987 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472034986 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_790'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472038886 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472042786 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_319'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472047486 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472051386 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472055485 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472060885 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472064885 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_535'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472068985 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472072885 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472076885 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_338'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472081184 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_641'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472084984 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472089084 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472093284 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472097284 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_9_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472101284 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_8_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472105983 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Unsqueeze_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472109983 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472113883 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_684'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472117783 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472121983 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_473'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472125982 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_352'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472129882 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472133782 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_384'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472137782 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_504'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472141782 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Unsqueeze_11_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472145682 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_382'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472150081 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_10_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472153981 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472157881 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_8_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472161781 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472165681 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472169581 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_488'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472173780 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/attention/self/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472177580 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_657'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472181480 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_5_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472186580 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_806'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472190680 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_533'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472194579 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_3_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472198479 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_506'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472202479 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_354'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472206479 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/attention/self/Constant_7_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472210379 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_775'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472214479 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_622'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472218578 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_624'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472222578 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_490'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472226478 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_2_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472230378 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_639'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472234378 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_471'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472238178 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472242077 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_655'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472245877 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/attention/self/Constant_4_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472249777 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/attention/self/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472253677 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_686'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.472549164 [I:onnxruntime:Default, concat_slice_elimination.cc:36 ApplyImpl] Total fused concat node count: 0\n",
      "2023-03-30 16:28:45.475793124 [I:onnxruntime:Default, propagate_cast_ops.cc:1463 ApplyImpl] Propagate Cast operations summary:\n",
      "2023-03-30 16:28:45.475805923 [I:onnxruntime:Default, propagate_cast_ops.cc:1464 ApplyImpl] Number of passes = 2\n",
      "2023-03-30 16:28:45.475810623 [I:onnxruntime:Default, propagate_cast_ops.cc:1465 ApplyImpl] Nodes Inserted:\n",
      "2023-03-30 16:28:45.475817323 [I:onnxruntime:Default, propagate_cast_ops.cc:1468 ApplyImpl] Nodes Removed:\n",
      "2023-03-30 16:28:45.475821623 [I:onnxruntime:Default, propagate_cast_ops.cc:1469 operator()] /Cast\n",
      "2023-03-30 16:28:45.475825523 [I:onnxruntime:Default, propagate_cast_ops.cc:1471 ApplyImpl] Nodes Converted to FP16:\n",
      "2023-03-30 16:28:45.478212320 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478224119 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.3/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478229919 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478233919 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.2/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478238818 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478243618 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/embeddings/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478249818 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478253818 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.0/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478257918 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/output/bottleneck/dropout/Constant_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.478261917 [I:onnxruntime:Default, graph.cc:3545 CleanUnusedInitializersAndNodeArgs] Removing initializer '/encoder/layer.1/output/bottleneck/dropout/Constant_1_output_0'. It is no longer used by any node.\n",
      "2023-03-30 16:28:45.480586917 [I:onnxruntime:Default, reshape_fusion.cc:53 ApplyImpl] Total fused reshape node count: 0\n",
      "2023-03-30 16:28:45.480742610 [I:onnxruntime:Default, concat_slice_elimination.cc:36 ApplyImpl] Total fused concat node count: 0\n",
      "2023-03-30 16:28:45.501968993 [I:onnxruntime:Default, gradient_graph_builder.cc:167 ReverseBFSWithStopGradient] Skip building gradient for input_1 of node: /embeddings/position_embeddings/Gather\n",
      "2023-03-30 16:28:45.502250681 [W:onnxruntime:Default, gradient_graph_builder.cc:116 GradientGraphBuilder] Following nodes are unreachable for gradient back propagation: /pooler/dense/Gemm, /pooler/dense/Gemm, \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "/onnxruntime_src/orttraining/orttraining/python/orttraining_pybind_state.cc:841 onnxruntime::python::addObjectMethodsForTraining(pybind11::module&, onnxruntime::python::ExecutionProviderRegistrationFn)::<lambda(onnxruntime::python::PyGradientGraphBuilder*)> [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Cannot compute the partial derivative for 'pooler.dense.bias' as it's unreachable from the output node(s).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m onnxblock\u001b[39m.\u001b[39monnx_model(onnx_model) \u001b[39mas\u001b[39;00m model_accessor:\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwithin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m block\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     loss_output_name \u001b[39m=\u001b[39m training_block(inference_model_output_name)\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtraining block initialized\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m     eval_model \u001b[39m=\u001b[39m model_accessor\u001b[39m.\u001b[39meval_model\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/onnxruntime/training/onnxblock/model.py:119\u001b[0m, in \u001b[0;36mTrainingModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39m=\u001b[39m graph_utils\u001b[39m.\u001b[39mget_model_parameters(\n\u001b[1;32m    115\u001b[0m     accessor\u001b[39m.\u001b[39mglobal_accessor\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_arg_not_requiring_grad\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[39m# build the gradient graph\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m all_args_requiring_gradient_names \u001b[39m=\u001b[39m graph_utils\u001b[39m.\u001b[39;49mbuild_gradient_graph(\n\u001b[1;32m    120\u001b[0m     accessor\u001b[39m.\u001b[39;49mglobal_accessor,\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arg_requiring_grad,\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arg_not_requiring_grad,\n\u001b[1;32m    123\u001b[0m     output,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[39m# add gradient accumulation nodes\u001b[39;00m\n\u001b[1;32m    127\u001b[0m graph_utils\u001b[39m.\u001b[39mbuild_gradient_accumulation_graph(accessor\u001b[39m.\u001b[39mglobal_accessor\u001b[39m.\u001b[39mmodel, all_args_requiring_gradient_names)\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/onnxruntime/training/onnxblock/_graph_utils.py:105\u001b[0m, in \u001b[0;36mbuild_gradient_graph\u001b[0;34m(accessor, user_args_requiring_grad, user_args_not_requiring_grad, output_names)\u001b[0m\n\u001b[1;32m     98\u001b[0m     output_names \u001b[39m=\u001b[39m [output_names]\n\u001b[1;32m     99\u001b[0m builder \u001b[39m=\u001b[39m GradientGraphBuilder(\n\u001b[1;32m    100\u001b[0m     model\u001b[39m.\u001b[39mSerializeToString(),\n\u001b[1;32m    101\u001b[0m     \u001b[39mset\u001b[39m(output_names),\n\u001b[1;32m    102\u001b[0m     \u001b[39mset\u001b[39m(all_args_requiring_gradient),\n\u001b[1;32m    103\u001b[0m     output_names[\u001b[39m0\u001b[39m],\n\u001b[1;32m    104\u001b[0m )\n\u001b[0;32m--> 105\u001b[0m builder\u001b[39m.\u001b[39;49mbuild()\n\u001b[1;32m    106\u001b[0m gradient_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload_from_string(builder\u001b[39m.\u001b[39mget_model())\n\u001b[1;32m    108\u001b[0m \u001b[39m# Reorder gradient outputs for the gradient model based on the all_args_requiring_gradient order\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /onnxruntime_src/orttraining/orttraining/python/orttraining_pybind_state.cc:841 onnxruntime::python::addObjectMethodsForTraining(pybind11::module&, onnxruntime::python::ExecutionProviderRegistrationFn)::<lambda(onnxruntime::python::PyGradientGraphBuilder*)> [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Cannot compute the partial derivative for 'pooler.dense.bias' as it's unreachable from the output node(s).\n"
     ]
    }
   ],
   "source": [
    "class MobileBERTWithLoss(onnxblock.TrainingModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = onnxblock.loss.CrossEntropyLoss()\n",
    "\n",
    "    def build(self, loss_node_input_name):\n",
    "        print('inside mobilebertwithloss build')\n",
    "        return self.loss(loss_node_input_name)\n",
    "\n",
    "\n",
    "# Load the model from the exported inference ONNX file.\n",
    "onnx_model = onnx.load(f\"training_artifacts/{model_name}.onnx\")\n",
    "print('done loading onnx model')\n",
    "eval_model = None\n",
    "optimizer_model = None\n",
    "\n",
    "training_block = MobileBERTWithLoss()\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        training_block.requires_grad(name)\n",
    "    else:\n",
    "        training_block.requires_grad(name, False)\n",
    "\n",
    "training_block.requires_grad('embeddings.position_ids', False)\n",
    "\n",
    "print('done creating trainingblock')\n",
    "\n",
    "inference_model_output_name = \"output\"\n",
    "with onnxblock.onnx_model(onnx_model) as model_accessor:\n",
    "    print('within \"with\" block')\n",
    "    loss_output_name = training_block(inference_model_output_name)\n",
    "    print('training block initialized')\n",
    "    eval_model = model_accessor.eval_model\n",
    "    print('eval model created')\n",
    "\n",
    "print('inference model done')\n",
    "\n",
    "optimizer_block = onnxblock.optim.AdamW()\n",
    "with onnxblock.onnx_model() as model_accessor:\n",
    "    optimizer_outputs = optimizer_block(training_block.parameters())\n",
    "    optimizer_model = model_accessor.model\n",
    "print('optimizer model done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnxblock.save_checkpoint(training_block.parameters(), f\"training_artifacts/{model_name}.ckpt\")\n",
    "onnx.save(onnx_model, f\"training_artifacts/{model_name}_training.onnx\")\n",
    "onnx.save(eval_model, f\"training_artifacts/{model_name}_eval.onnx\")\n",
    "onnx.save(optimizer_model, f\"training_artifacts/{model_name}_optimizer.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, pad_to_len):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "    # filter out empty strings\n",
    "    examples[\"text\"] = [sent for sent in examples[\"text\"] if len(sent) > 0]\n",
    "    return tokenizer(examples[\"text\"], return_special_tokens_mask=True, padding=\"max_length\", max_length=pad_to_len, truncation=True)\n",
    "\n",
    "def generate_tokens(corpus):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with a \"text\" feature.\n",
    "\n",
    "    Returns a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "    \"\"\"\n",
    "    # pad_to_len must be calculated before the batching happens to create consistent sizes in the resulting tensor\n",
    "    # pad_to_len = max([len(sent) for sent in corpus[\"text\"]])\n",
    "    pad_to_len = 150 # shortened for demonstration purposes\n",
    "    return corpus.map(tokenize_function, batched=True, fn_kwargs={\"pad_to_len\": pad_to_len})\n",
    "\n",
    "def generate_json_dict(token_dataset):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "\n",
    "    Basically changes the 2d Python lists into two fields: a shape & a flattened list, for easier conversion to OnnxValues\n",
    "\n",
    "    Returns a dictionary with the following keys: input_ids, input_size, token_type_ids, token_type_size, attention_mask, attention_mask_size, special_tokens_mask, special_tokens_size\n",
    "    \"\"\"\n",
    "    json_dict = {}\n",
    "    keys_to_convert = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"special_tokens_mask\"]\n",
    "\n",
    "    for key_name in keys_to_convert:\n",
    "        # add field for the shape of the tensor\n",
    "        json_dict[key_name + \"_shape\"] = [len(token_dataset[key_name]), len(token_dataset[key_name][0])]\n",
    "        # flatten list\n",
    "        json_dict[key_name] = [num for sent in token_dataset[key_name] for num in sent]\n",
    "    \n",
    "    return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|| 3/3 [00:00<00:00, 733.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"wikitext\" \n",
    "dataset_config = \"wikitext-2-v1\"\n",
    "# corpus = type DatasetDict with three Datasets: test, train, validation\n",
    "corpus = load_dataset(dataset_name, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "#corpus[\"train\"][\"text\"]\n",
    "# max([len(sent) for sent in corpus[\"train\"][\"text\"]])\n",
    "# 3837\n",
    "#len(corpus[\"train\"][\"text\"])\n",
    "# 36718\n",
    "\n",
    "train_test = generate_tokens(corpus[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23767\n",
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_test[\"input_ids\"]))\n",
    "# 36718\n",
    "print(len(train_test[\"input_ids\"][0]))\n",
    "# 3837\n",
    "\n",
    "max([len(sent) for sent in train_test[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b83d710dd1d17dd2.arrow\n",
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-f91b7e5c1178149a.arrow\n",
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-aa24fc21c9608d06.arrow\n"
     ]
    }
   ],
   "source": [
    "test_tokens = generate_tokens(corpus[\"test\"])\n",
    "test_tokens = generate_json_dict(test_tokens)\n",
    "train_tokens = generate_tokens(corpus[\"train\"])\n",
    "train_tokens = generate_json_dict(train_tokens)\n",
    "validation_tokens = generate_tokens(corpus[\"validation\"])\n",
    "validation_tokens = generate_json_dict(validation_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all the tokens to a json file\n",
    "file_names = [\"test_tokens.json\", \"train_tokens.json\", \"validation_tokens.json\"]\n",
    "token_dicts = [test_tokens, train_tokens, validation_tokens]\n",
    "\n",
    "def write_dicts_to_files(file_names, dicts):\n",
    "    # assumes file_names and dicts are 2 lists w/ the same lengths\n",
    "    for i in range(len(file_names)):\n",
    "        with open(file_names[i], \"w\") as json_file:\n",
    "            json.dump(dicts[i], json_file)\n",
    "\n",
    "write_dicts_to_files(file_names, token_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
