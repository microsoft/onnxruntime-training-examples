{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import onnx\n",
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertConfig\n",
    "model = transformers.AutoModel.from_pretrained('google/mobilebert-uncased', MobileBertConfig(num_hidden_layers=4))\n",
    "# model = transformers.AutoModel.from_pretrained('google/mobilebert-uncased')\n",
    "model_name = 'mobilebert-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random input\n",
    "\n",
    "# expects\n",
    "# input_ids = torch.LongTensor of shape (batch size, seq len)\n",
    "# attention_mask = torch.FloatTensor of shape (batch size, seq len)\n",
    "# token_type_ids = torch.LongTensor of shape (bs, seq len)\n",
    "\n",
    "num_seq = 25\n",
    "seq_len = 150\n",
    "vocab = 20000\n",
    "input_ids = torch.randint(vocab, (num_seq, seq_len))\n",
    "attention_mask = torch.ones((num_seq, seq_len), dtype=torch.float)\n",
    "token_type_ids = torch.ones((num_seq, seq_len), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(1000),\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:967: UserWarning: Warning: ONNX export of embedding with padding_idx >= 0 for training mode. ONNX does not support not updating the embedding vector at padding_idx during training.\n",
      "  warnings.warn(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/bert_ort/carolinezhu/newe2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, (input_ids, attention_mask, token_type_ids),\n",
    "                  f\"training_artifacts_dynamic/{model_name}.onnx\", \n",
    "                  input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "                  output_names=[\"output\"],\n",
    "                   dynamic_axes={\n",
    "                     \"input_ids\": {0: \"num_seq\"},\n",
    "                     \"attention_mask\": {0: \"num_seq\"},\n",
    "                     \"token_type_ids\": {0: \"num_seq\"}\n",
    "                   },\n",
    "                   export_params=True, \n",
    "                   do_constant_folding=False,\n",
    "                   training=torch.onnx.TrainingMode.TRAINING)\n",
    "\n",
    "# torch.onnx.export(model, (input_ids, attention_mask, token_type_ids),\n",
    "#                   f\"training_artifacts/{model_name}.onnx\", \n",
    "#                   input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "#                   output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight True\n",
      "embeddings.position_embeddings.weight True\n",
      "embeddings.token_type_embeddings.weight True\n",
      "embeddings.embedding_transformation.weight True\n",
      "embeddings.embedding_transformation.bias True\n",
      "embeddings.LayerNorm.bias True\n",
      "embeddings.LayerNorm.weight True\n",
      "encoder.layer.0.attention.self.query.weight True\n",
      "encoder.layer.0.attention.self.query.bias True\n",
      "encoder.layer.0.attention.self.key.weight True\n",
      "encoder.layer.0.attention.self.key.bias True\n",
      "encoder.layer.0.attention.self.value.weight True\n",
      "encoder.layer.0.attention.self.value.bias True\n",
      "encoder.layer.0.attention.output.dense.weight True\n",
      "encoder.layer.0.attention.output.dense.bias True\n",
      "encoder.layer.0.attention.output.LayerNorm.bias True\n",
      "encoder.layer.0.attention.output.LayerNorm.weight True\n",
      "encoder.layer.0.intermediate.dense.weight True\n",
      "encoder.layer.0.intermediate.dense.bias True\n",
      "encoder.layer.0.output.dense.weight True\n",
      "encoder.layer.0.output.dense.bias True\n",
      "encoder.layer.0.output.LayerNorm.bias True\n",
      "encoder.layer.0.output.LayerNorm.weight True\n",
      "encoder.layer.0.output.bottleneck.dense.weight True\n",
      "encoder.layer.0.output.bottleneck.dense.bias True\n",
      "encoder.layer.0.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.0.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.0.bottleneck.input.dense.weight True\n",
      "encoder.layer.0.bottleneck.input.dense.bias True\n",
      "encoder.layer.0.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.0.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.0.bottleneck.attention.dense.weight True\n",
      "encoder.layer.0.bottleneck.attention.dense.bias True\n",
      "encoder.layer.0.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.0.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.0.output.dense.weight True\n",
      "encoder.layer.0.ffn.0.output.dense.bias True\n",
      "encoder.layer.0.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.1.output.dense.weight True\n",
      "encoder.layer.0.ffn.1.output.dense.bias True\n",
      "encoder.layer.0.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.0.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.0.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.0.ffn.2.output.dense.weight True\n",
      "encoder.layer.0.ffn.2.output.dense.bias True\n",
      "encoder.layer.0.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.0.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.1.attention.self.query.weight True\n",
      "encoder.layer.1.attention.self.query.bias True\n",
      "encoder.layer.1.attention.self.key.weight True\n",
      "encoder.layer.1.attention.self.key.bias True\n",
      "encoder.layer.1.attention.self.value.weight True\n",
      "encoder.layer.1.attention.self.value.bias True\n",
      "encoder.layer.1.attention.output.dense.weight True\n",
      "encoder.layer.1.attention.output.dense.bias True\n",
      "encoder.layer.1.attention.output.LayerNorm.bias True\n",
      "encoder.layer.1.attention.output.LayerNorm.weight True\n",
      "encoder.layer.1.intermediate.dense.weight True\n",
      "encoder.layer.1.intermediate.dense.bias True\n",
      "encoder.layer.1.output.dense.weight True\n",
      "encoder.layer.1.output.dense.bias True\n",
      "encoder.layer.1.output.LayerNorm.bias True\n",
      "encoder.layer.1.output.LayerNorm.weight True\n",
      "encoder.layer.1.output.bottleneck.dense.weight True\n",
      "encoder.layer.1.output.bottleneck.dense.bias True\n",
      "encoder.layer.1.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.1.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.1.bottleneck.input.dense.weight True\n",
      "encoder.layer.1.bottleneck.input.dense.bias True\n",
      "encoder.layer.1.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.1.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.1.bottleneck.attention.dense.weight True\n",
      "encoder.layer.1.bottleneck.attention.dense.bias True\n",
      "encoder.layer.1.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.1.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.0.output.dense.weight True\n",
      "encoder.layer.1.ffn.0.output.dense.bias True\n",
      "encoder.layer.1.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.1.output.dense.weight True\n",
      "encoder.layer.1.ffn.1.output.dense.bias True\n",
      "encoder.layer.1.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.1.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.1.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.1.ffn.2.output.dense.weight True\n",
      "encoder.layer.1.ffn.2.output.dense.bias True\n",
      "encoder.layer.1.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.1.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.2.attention.self.query.weight True\n",
      "encoder.layer.2.attention.self.query.bias True\n",
      "encoder.layer.2.attention.self.key.weight True\n",
      "encoder.layer.2.attention.self.key.bias True\n",
      "encoder.layer.2.attention.self.value.weight True\n",
      "encoder.layer.2.attention.self.value.bias True\n",
      "encoder.layer.2.attention.output.dense.weight True\n",
      "encoder.layer.2.attention.output.dense.bias True\n",
      "encoder.layer.2.attention.output.LayerNorm.bias True\n",
      "encoder.layer.2.attention.output.LayerNorm.weight True\n",
      "encoder.layer.2.intermediate.dense.weight True\n",
      "encoder.layer.2.intermediate.dense.bias True\n",
      "encoder.layer.2.output.dense.weight True\n",
      "encoder.layer.2.output.dense.bias True\n",
      "encoder.layer.2.output.LayerNorm.bias True\n",
      "encoder.layer.2.output.LayerNorm.weight True\n",
      "encoder.layer.2.output.bottleneck.dense.weight True\n",
      "encoder.layer.2.output.bottleneck.dense.bias True\n",
      "encoder.layer.2.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.2.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.2.bottleneck.input.dense.weight True\n",
      "encoder.layer.2.bottleneck.input.dense.bias True\n",
      "encoder.layer.2.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.2.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.2.bottleneck.attention.dense.weight True\n",
      "encoder.layer.2.bottleneck.attention.dense.bias True\n",
      "encoder.layer.2.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.2.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.0.output.dense.weight True\n",
      "encoder.layer.2.ffn.0.output.dense.bias True\n",
      "encoder.layer.2.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.1.output.dense.weight True\n",
      "encoder.layer.2.ffn.1.output.dense.bias True\n",
      "encoder.layer.2.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.2.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.2.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.2.ffn.2.output.dense.weight True\n",
      "encoder.layer.2.ffn.2.output.dense.bias True\n",
      "encoder.layer.2.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.2.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.3.attention.self.query.weight True\n",
      "encoder.layer.3.attention.self.query.bias True\n",
      "encoder.layer.3.attention.self.key.weight True\n",
      "encoder.layer.3.attention.self.key.bias True\n",
      "encoder.layer.3.attention.self.value.weight True\n",
      "encoder.layer.3.attention.self.value.bias True\n",
      "encoder.layer.3.attention.output.dense.weight True\n",
      "encoder.layer.3.attention.output.dense.bias True\n",
      "encoder.layer.3.attention.output.LayerNorm.bias True\n",
      "encoder.layer.3.attention.output.LayerNorm.weight True\n",
      "encoder.layer.3.intermediate.dense.weight True\n",
      "encoder.layer.3.intermediate.dense.bias True\n",
      "encoder.layer.3.output.dense.weight True\n",
      "encoder.layer.3.output.dense.bias True\n",
      "encoder.layer.3.output.LayerNorm.bias True\n",
      "encoder.layer.3.output.LayerNorm.weight True\n",
      "encoder.layer.3.output.bottleneck.dense.weight True\n",
      "encoder.layer.3.output.bottleneck.dense.bias True\n",
      "encoder.layer.3.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.3.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.3.bottleneck.input.dense.weight True\n",
      "encoder.layer.3.bottleneck.input.dense.bias True\n",
      "encoder.layer.3.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.3.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.3.bottleneck.attention.dense.weight True\n",
      "encoder.layer.3.bottleneck.attention.dense.bias True\n",
      "encoder.layer.3.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.3.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.0.output.dense.weight True\n",
      "encoder.layer.3.ffn.0.output.dense.bias True\n",
      "encoder.layer.3.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.1.output.dense.weight True\n",
      "encoder.layer.3.ffn.1.output.dense.bias True\n",
      "encoder.layer.3.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.3.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.3.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.3.ffn.2.output.dense.weight True\n",
      "encoder.layer.3.ffn.2.output.dense.bias True\n",
      "encoder.layer.3.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.3.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.4.attention.self.query.weight True\n",
      "encoder.layer.4.attention.self.query.bias True\n",
      "encoder.layer.4.attention.self.key.weight True\n",
      "encoder.layer.4.attention.self.key.bias True\n",
      "encoder.layer.4.attention.self.value.weight True\n",
      "encoder.layer.4.attention.self.value.bias True\n",
      "encoder.layer.4.attention.output.dense.weight True\n",
      "encoder.layer.4.attention.output.dense.bias True\n",
      "encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "encoder.layer.4.intermediate.dense.weight True\n",
      "encoder.layer.4.intermediate.dense.bias True\n",
      "encoder.layer.4.output.dense.weight True\n",
      "encoder.layer.4.output.dense.bias True\n",
      "encoder.layer.4.output.LayerNorm.bias True\n",
      "encoder.layer.4.output.LayerNorm.weight True\n",
      "encoder.layer.4.output.bottleneck.dense.weight True\n",
      "encoder.layer.4.output.bottleneck.dense.bias True\n",
      "encoder.layer.4.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.4.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.4.bottleneck.input.dense.weight True\n",
      "encoder.layer.4.bottleneck.input.dense.bias True\n",
      "encoder.layer.4.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.4.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.4.bottleneck.attention.dense.weight True\n",
      "encoder.layer.4.bottleneck.attention.dense.bias True\n",
      "encoder.layer.4.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.4.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.0.output.dense.weight True\n",
      "encoder.layer.4.ffn.0.output.dense.bias True\n",
      "encoder.layer.4.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.1.output.dense.weight True\n",
      "encoder.layer.4.ffn.1.output.dense.bias True\n",
      "encoder.layer.4.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.4.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.4.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.4.ffn.2.output.dense.weight True\n",
      "encoder.layer.4.ffn.2.output.dense.bias True\n",
      "encoder.layer.4.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.4.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.5.attention.self.query.weight True\n",
      "encoder.layer.5.attention.self.query.bias True\n",
      "encoder.layer.5.attention.self.key.weight True\n",
      "encoder.layer.5.attention.self.key.bias True\n",
      "encoder.layer.5.attention.self.value.weight True\n",
      "encoder.layer.5.attention.self.value.bias True\n",
      "encoder.layer.5.attention.output.dense.weight True\n",
      "encoder.layer.5.attention.output.dense.bias True\n",
      "encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "encoder.layer.5.intermediate.dense.weight True\n",
      "encoder.layer.5.intermediate.dense.bias True\n",
      "encoder.layer.5.output.dense.weight True\n",
      "encoder.layer.5.output.dense.bias True\n",
      "encoder.layer.5.output.LayerNorm.bias True\n",
      "encoder.layer.5.output.LayerNorm.weight True\n",
      "encoder.layer.5.output.bottleneck.dense.weight True\n",
      "encoder.layer.5.output.bottleneck.dense.bias True\n",
      "encoder.layer.5.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.5.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.5.bottleneck.input.dense.weight True\n",
      "encoder.layer.5.bottleneck.input.dense.bias True\n",
      "encoder.layer.5.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.5.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.5.bottleneck.attention.dense.weight True\n",
      "encoder.layer.5.bottleneck.attention.dense.bias True\n",
      "encoder.layer.5.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.5.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.0.output.dense.weight True\n",
      "encoder.layer.5.ffn.0.output.dense.bias True\n",
      "encoder.layer.5.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.1.output.dense.weight True\n",
      "encoder.layer.5.ffn.1.output.dense.bias True\n",
      "encoder.layer.5.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.5.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.5.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.5.ffn.2.output.dense.weight True\n",
      "encoder.layer.5.ffn.2.output.dense.bias True\n",
      "encoder.layer.5.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.5.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.6.attention.self.query.weight True\n",
      "encoder.layer.6.attention.self.query.bias True\n",
      "encoder.layer.6.attention.self.key.weight True\n",
      "encoder.layer.6.attention.self.key.bias True\n",
      "encoder.layer.6.attention.self.value.weight True\n",
      "encoder.layer.6.attention.self.value.bias True\n",
      "encoder.layer.6.attention.output.dense.weight True\n",
      "encoder.layer.6.attention.output.dense.bias True\n",
      "encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "encoder.layer.6.intermediate.dense.weight True\n",
      "encoder.layer.6.intermediate.dense.bias True\n",
      "encoder.layer.6.output.dense.weight True\n",
      "encoder.layer.6.output.dense.bias True\n",
      "encoder.layer.6.output.LayerNorm.bias True\n",
      "encoder.layer.6.output.LayerNorm.weight True\n",
      "encoder.layer.6.output.bottleneck.dense.weight True\n",
      "encoder.layer.6.output.bottleneck.dense.bias True\n",
      "encoder.layer.6.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.6.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.6.bottleneck.input.dense.weight True\n",
      "encoder.layer.6.bottleneck.input.dense.bias True\n",
      "encoder.layer.6.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.6.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.6.bottleneck.attention.dense.weight True\n",
      "encoder.layer.6.bottleneck.attention.dense.bias True\n",
      "encoder.layer.6.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.6.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.0.output.dense.weight True\n",
      "encoder.layer.6.ffn.0.output.dense.bias True\n",
      "encoder.layer.6.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.1.output.dense.weight True\n",
      "encoder.layer.6.ffn.1.output.dense.bias True\n",
      "encoder.layer.6.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.6.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.6.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.6.ffn.2.output.dense.weight True\n",
      "encoder.layer.6.ffn.2.output.dense.bias True\n",
      "encoder.layer.6.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.6.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.7.attention.self.query.weight True\n",
      "encoder.layer.7.attention.self.query.bias True\n",
      "encoder.layer.7.attention.self.key.weight True\n",
      "encoder.layer.7.attention.self.key.bias True\n",
      "encoder.layer.7.attention.self.value.weight True\n",
      "encoder.layer.7.attention.self.value.bias True\n",
      "encoder.layer.7.attention.output.dense.weight True\n",
      "encoder.layer.7.attention.output.dense.bias True\n",
      "encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "encoder.layer.7.intermediate.dense.weight True\n",
      "encoder.layer.7.intermediate.dense.bias True\n",
      "encoder.layer.7.output.dense.weight True\n",
      "encoder.layer.7.output.dense.bias True\n",
      "encoder.layer.7.output.LayerNorm.bias True\n",
      "encoder.layer.7.output.LayerNorm.weight True\n",
      "encoder.layer.7.output.bottleneck.dense.weight True\n",
      "encoder.layer.7.output.bottleneck.dense.bias True\n",
      "encoder.layer.7.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.7.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.7.bottleneck.input.dense.weight True\n",
      "encoder.layer.7.bottleneck.input.dense.bias True\n",
      "encoder.layer.7.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.7.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.7.bottleneck.attention.dense.weight True\n",
      "encoder.layer.7.bottleneck.attention.dense.bias True\n",
      "encoder.layer.7.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.7.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.0.output.dense.weight True\n",
      "encoder.layer.7.ffn.0.output.dense.bias True\n",
      "encoder.layer.7.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.1.output.dense.weight True\n",
      "encoder.layer.7.ffn.1.output.dense.bias True\n",
      "encoder.layer.7.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.7.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.7.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.7.ffn.2.output.dense.weight True\n",
      "encoder.layer.7.ffn.2.output.dense.bias True\n",
      "encoder.layer.7.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.7.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.8.attention.self.query.weight True\n",
      "encoder.layer.8.attention.self.query.bias True\n",
      "encoder.layer.8.attention.self.key.weight True\n",
      "encoder.layer.8.attention.self.key.bias True\n",
      "encoder.layer.8.attention.self.value.weight True\n",
      "encoder.layer.8.attention.self.value.bias True\n",
      "encoder.layer.8.attention.output.dense.weight True\n",
      "encoder.layer.8.attention.output.dense.bias True\n",
      "encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "encoder.layer.8.intermediate.dense.weight True\n",
      "encoder.layer.8.intermediate.dense.bias True\n",
      "encoder.layer.8.output.dense.weight True\n",
      "encoder.layer.8.output.dense.bias True\n",
      "encoder.layer.8.output.LayerNorm.bias True\n",
      "encoder.layer.8.output.LayerNorm.weight True\n",
      "encoder.layer.8.output.bottleneck.dense.weight True\n",
      "encoder.layer.8.output.bottleneck.dense.bias True\n",
      "encoder.layer.8.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.8.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.8.bottleneck.input.dense.weight True\n",
      "encoder.layer.8.bottleneck.input.dense.bias True\n",
      "encoder.layer.8.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.8.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.8.bottleneck.attention.dense.weight True\n",
      "encoder.layer.8.bottleneck.attention.dense.bias True\n",
      "encoder.layer.8.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.8.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.0.output.dense.weight True\n",
      "encoder.layer.8.ffn.0.output.dense.bias True\n",
      "encoder.layer.8.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.1.output.dense.weight True\n",
      "encoder.layer.8.ffn.1.output.dense.bias True\n",
      "encoder.layer.8.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.8.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.8.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.8.ffn.2.output.dense.weight True\n",
      "encoder.layer.8.ffn.2.output.dense.bias True\n",
      "encoder.layer.8.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.8.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.9.attention.self.query.weight True\n",
      "encoder.layer.9.attention.self.query.bias True\n",
      "encoder.layer.9.attention.self.key.weight True\n",
      "encoder.layer.9.attention.self.key.bias True\n",
      "encoder.layer.9.attention.self.value.weight True\n",
      "encoder.layer.9.attention.self.value.bias True\n",
      "encoder.layer.9.attention.output.dense.weight True\n",
      "encoder.layer.9.attention.output.dense.bias True\n",
      "encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "encoder.layer.9.intermediate.dense.weight True\n",
      "encoder.layer.9.intermediate.dense.bias True\n",
      "encoder.layer.9.output.dense.weight True\n",
      "encoder.layer.9.output.dense.bias True\n",
      "encoder.layer.9.output.LayerNorm.bias True\n",
      "encoder.layer.9.output.LayerNorm.weight True\n",
      "encoder.layer.9.output.bottleneck.dense.weight True\n",
      "encoder.layer.9.output.bottleneck.dense.bias True\n",
      "encoder.layer.9.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.9.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.9.bottleneck.input.dense.weight True\n",
      "encoder.layer.9.bottleneck.input.dense.bias True\n",
      "encoder.layer.9.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.9.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.9.bottleneck.attention.dense.weight True\n",
      "encoder.layer.9.bottleneck.attention.dense.bias True\n",
      "encoder.layer.9.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.9.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.0.output.dense.weight True\n",
      "encoder.layer.9.ffn.0.output.dense.bias True\n",
      "encoder.layer.9.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.1.output.dense.weight True\n",
      "encoder.layer.9.ffn.1.output.dense.bias True\n",
      "encoder.layer.9.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.9.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.9.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.9.ffn.2.output.dense.weight True\n",
      "encoder.layer.9.ffn.2.output.dense.bias True\n",
      "encoder.layer.9.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.9.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.10.attention.self.query.weight True\n",
      "encoder.layer.10.attention.self.query.bias True\n",
      "encoder.layer.10.attention.self.key.weight True\n",
      "encoder.layer.10.attention.self.key.bias True\n",
      "encoder.layer.10.attention.self.value.weight True\n",
      "encoder.layer.10.attention.self.value.bias True\n",
      "encoder.layer.10.attention.output.dense.weight True\n",
      "encoder.layer.10.attention.output.dense.bias True\n",
      "encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "encoder.layer.10.intermediate.dense.weight True\n",
      "encoder.layer.10.intermediate.dense.bias True\n",
      "encoder.layer.10.output.dense.weight True\n",
      "encoder.layer.10.output.dense.bias True\n",
      "encoder.layer.10.output.LayerNorm.bias True\n",
      "encoder.layer.10.output.LayerNorm.weight True\n",
      "encoder.layer.10.output.bottleneck.dense.weight True\n",
      "encoder.layer.10.output.bottleneck.dense.bias True\n",
      "encoder.layer.10.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.10.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.10.bottleneck.input.dense.weight True\n",
      "encoder.layer.10.bottleneck.input.dense.bias True\n",
      "encoder.layer.10.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.10.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.10.bottleneck.attention.dense.weight True\n",
      "encoder.layer.10.bottleneck.attention.dense.bias True\n",
      "encoder.layer.10.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.10.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.0.output.dense.weight True\n",
      "encoder.layer.10.ffn.0.output.dense.bias True\n",
      "encoder.layer.10.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.1.output.dense.weight True\n",
      "encoder.layer.10.ffn.1.output.dense.bias True\n",
      "encoder.layer.10.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.10.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.10.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.10.ffn.2.output.dense.weight True\n",
      "encoder.layer.10.ffn.2.output.dense.bias True\n",
      "encoder.layer.10.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.10.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.11.attention.self.query.weight True\n",
      "encoder.layer.11.attention.self.query.bias True\n",
      "encoder.layer.11.attention.self.key.weight True\n",
      "encoder.layer.11.attention.self.key.bias True\n",
      "encoder.layer.11.attention.self.value.weight True\n",
      "encoder.layer.11.attention.self.value.bias True\n",
      "encoder.layer.11.attention.output.dense.weight True\n",
      "encoder.layer.11.attention.output.dense.bias True\n",
      "encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "encoder.layer.11.intermediate.dense.weight True\n",
      "encoder.layer.11.intermediate.dense.bias True\n",
      "encoder.layer.11.output.dense.weight True\n",
      "encoder.layer.11.output.dense.bias True\n",
      "encoder.layer.11.output.LayerNorm.bias True\n",
      "encoder.layer.11.output.LayerNorm.weight True\n",
      "encoder.layer.11.output.bottleneck.dense.weight True\n",
      "encoder.layer.11.output.bottleneck.dense.bias True\n",
      "encoder.layer.11.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.11.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.11.bottleneck.input.dense.weight True\n",
      "encoder.layer.11.bottleneck.input.dense.bias True\n",
      "encoder.layer.11.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.11.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.11.bottleneck.attention.dense.weight True\n",
      "encoder.layer.11.bottleneck.attention.dense.bias True\n",
      "encoder.layer.11.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.11.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.0.output.dense.weight True\n",
      "encoder.layer.11.ffn.0.output.dense.bias True\n",
      "encoder.layer.11.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.1.output.dense.weight True\n",
      "encoder.layer.11.ffn.1.output.dense.bias True\n",
      "encoder.layer.11.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.11.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.11.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.11.ffn.2.output.dense.weight True\n",
      "encoder.layer.11.ffn.2.output.dense.bias True\n",
      "encoder.layer.11.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.11.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.12.attention.self.query.weight True\n",
      "encoder.layer.12.attention.self.query.bias True\n",
      "encoder.layer.12.attention.self.key.weight True\n",
      "encoder.layer.12.attention.self.key.bias True\n",
      "encoder.layer.12.attention.self.value.weight True\n",
      "encoder.layer.12.attention.self.value.bias True\n",
      "encoder.layer.12.attention.output.dense.weight True\n",
      "encoder.layer.12.attention.output.dense.bias True\n",
      "encoder.layer.12.attention.output.LayerNorm.bias True\n",
      "encoder.layer.12.attention.output.LayerNorm.weight True\n",
      "encoder.layer.12.intermediate.dense.weight True\n",
      "encoder.layer.12.intermediate.dense.bias True\n",
      "encoder.layer.12.output.dense.weight True\n",
      "encoder.layer.12.output.dense.bias True\n",
      "encoder.layer.12.output.LayerNorm.bias True\n",
      "encoder.layer.12.output.LayerNorm.weight True\n",
      "encoder.layer.12.output.bottleneck.dense.weight True\n",
      "encoder.layer.12.output.bottleneck.dense.bias True\n",
      "encoder.layer.12.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.12.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.12.bottleneck.input.dense.weight True\n",
      "encoder.layer.12.bottleneck.input.dense.bias True\n",
      "encoder.layer.12.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.12.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.12.bottleneck.attention.dense.weight True\n",
      "encoder.layer.12.bottleneck.attention.dense.bias True\n",
      "encoder.layer.12.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.12.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.0.output.dense.weight True\n",
      "encoder.layer.12.ffn.0.output.dense.bias True\n",
      "encoder.layer.12.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.1.output.dense.weight True\n",
      "encoder.layer.12.ffn.1.output.dense.bias True\n",
      "encoder.layer.12.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.12.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.12.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.12.ffn.2.output.dense.weight True\n",
      "encoder.layer.12.ffn.2.output.dense.bias True\n",
      "encoder.layer.12.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.12.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.13.attention.self.query.weight True\n",
      "encoder.layer.13.attention.self.query.bias True\n",
      "encoder.layer.13.attention.self.key.weight True\n",
      "encoder.layer.13.attention.self.key.bias True\n",
      "encoder.layer.13.attention.self.value.weight True\n",
      "encoder.layer.13.attention.self.value.bias True\n",
      "encoder.layer.13.attention.output.dense.weight True\n",
      "encoder.layer.13.attention.output.dense.bias True\n",
      "encoder.layer.13.attention.output.LayerNorm.bias True\n",
      "encoder.layer.13.attention.output.LayerNorm.weight True\n",
      "encoder.layer.13.intermediate.dense.weight True\n",
      "encoder.layer.13.intermediate.dense.bias True\n",
      "encoder.layer.13.output.dense.weight True\n",
      "encoder.layer.13.output.dense.bias True\n",
      "encoder.layer.13.output.LayerNorm.bias True\n",
      "encoder.layer.13.output.LayerNorm.weight True\n",
      "encoder.layer.13.output.bottleneck.dense.weight True\n",
      "encoder.layer.13.output.bottleneck.dense.bias True\n",
      "encoder.layer.13.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.13.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.13.bottleneck.input.dense.weight True\n",
      "encoder.layer.13.bottleneck.input.dense.bias True\n",
      "encoder.layer.13.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.13.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.13.bottleneck.attention.dense.weight True\n",
      "encoder.layer.13.bottleneck.attention.dense.bias True\n",
      "encoder.layer.13.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.13.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.0.output.dense.weight True\n",
      "encoder.layer.13.ffn.0.output.dense.bias True\n",
      "encoder.layer.13.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.1.output.dense.weight True\n",
      "encoder.layer.13.ffn.1.output.dense.bias True\n",
      "encoder.layer.13.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.13.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.13.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.13.ffn.2.output.dense.weight True\n",
      "encoder.layer.13.ffn.2.output.dense.bias True\n",
      "encoder.layer.13.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.13.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.14.attention.self.query.weight True\n",
      "encoder.layer.14.attention.self.query.bias True\n",
      "encoder.layer.14.attention.self.key.weight True\n",
      "encoder.layer.14.attention.self.key.bias True\n",
      "encoder.layer.14.attention.self.value.weight True\n",
      "encoder.layer.14.attention.self.value.bias True\n",
      "encoder.layer.14.attention.output.dense.weight True\n",
      "encoder.layer.14.attention.output.dense.bias True\n",
      "encoder.layer.14.attention.output.LayerNorm.bias True\n",
      "encoder.layer.14.attention.output.LayerNorm.weight True\n",
      "encoder.layer.14.intermediate.dense.weight True\n",
      "encoder.layer.14.intermediate.dense.bias True\n",
      "encoder.layer.14.output.dense.weight True\n",
      "encoder.layer.14.output.dense.bias True\n",
      "encoder.layer.14.output.LayerNorm.bias True\n",
      "encoder.layer.14.output.LayerNorm.weight True\n",
      "encoder.layer.14.output.bottleneck.dense.weight True\n",
      "encoder.layer.14.output.bottleneck.dense.bias True\n",
      "encoder.layer.14.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.14.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.14.bottleneck.input.dense.weight True\n",
      "encoder.layer.14.bottleneck.input.dense.bias True\n",
      "encoder.layer.14.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.14.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.14.bottleneck.attention.dense.weight True\n",
      "encoder.layer.14.bottleneck.attention.dense.bias True\n",
      "encoder.layer.14.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.14.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.0.output.dense.weight True\n",
      "encoder.layer.14.ffn.0.output.dense.bias True\n",
      "encoder.layer.14.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.1.output.dense.weight True\n",
      "encoder.layer.14.ffn.1.output.dense.bias True\n",
      "encoder.layer.14.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.14.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.14.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.14.ffn.2.output.dense.weight True\n",
      "encoder.layer.14.ffn.2.output.dense.bias True\n",
      "encoder.layer.14.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.14.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.15.attention.self.query.weight True\n",
      "encoder.layer.15.attention.self.query.bias True\n",
      "encoder.layer.15.attention.self.key.weight True\n",
      "encoder.layer.15.attention.self.key.bias True\n",
      "encoder.layer.15.attention.self.value.weight True\n",
      "encoder.layer.15.attention.self.value.bias True\n",
      "encoder.layer.15.attention.output.dense.weight True\n",
      "encoder.layer.15.attention.output.dense.bias True\n",
      "encoder.layer.15.attention.output.LayerNorm.bias True\n",
      "encoder.layer.15.attention.output.LayerNorm.weight True\n",
      "encoder.layer.15.intermediate.dense.weight True\n",
      "encoder.layer.15.intermediate.dense.bias True\n",
      "encoder.layer.15.output.dense.weight True\n",
      "encoder.layer.15.output.dense.bias True\n",
      "encoder.layer.15.output.LayerNorm.bias True\n",
      "encoder.layer.15.output.LayerNorm.weight True\n",
      "encoder.layer.15.output.bottleneck.dense.weight True\n",
      "encoder.layer.15.output.bottleneck.dense.bias True\n",
      "encoder.layer.15.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.15.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.15.bottleneck.input.dense.weight True\n",
      "encoder.layer.15.bottleneck.input.dense.bias True\n",
      "encoder.layer.15.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.15.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.15.bottleneck.attention.dense.weight True\n",
      "encoder.layer.15.bottleneck.attention.dense.bias True\n",
      "encoder.layer.15.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.15.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.0.output.dense.weight True\n",
      "encoder.layer.15.ffn.0.output.dense.bias True\n",
      "encoder.layer.15.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.1.output.dense.weight True\n",
      "encoder.layer.15.ffn.1.output.dense.bias True\n",
      "encoder.layer.15.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.15.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.15.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.15.ffn.2.output.dense.weight True\n",
      "encoder.layer.15.ffn.2.output.dense.bias True\n",
      "encoder.layer.15.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.15.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.16.attention.self.query.weight True\n",
      "encoder.layer.16.attention.self.query.bias True\n",
      "encoder.layer.16.attention.self.key.weight True\n",
      "encoder.layer.16.attention.self.key.bias True\n",
      "encoder.layer.16.attention.self.value.weight True\n",
      "encoder.layer.16.attention.self.value.bias True\n",
      "encoder.layer.16.attention.output.dense.weight True\n",
      "encoder.layer.16.attention.output.dense.bias True\n",
      "encoder.layer.16.attention.output.LayerNorm.bias True\n",
      "encoder.layer.16.attention.output.LayerNorm.weight True\n",
      "encoder.layer.16.intermediate.dense.weight True\n",
      "encoder.layer.16.intermediate.dense.bias True\n",
      "encoder.layer.16.output.dense.weight True\n",
      "encoder.layer.16.output.dense.bias True\n",
      "encoder.layer.16.output.LayerNorm.bias True\n",
      "encoder.layer.16.output.LayerNorm.weight True\n",
      "encoder.layer.16.output.bottleneck.dense.weight True\n",
      "encoder.layer.16.output.bottleneck.dense.bias True\n",
      "encoder.layer.16.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.16.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.16.bottleneck.input.dense.weight True\n",
      "encoder.layer.16.bottleneck.input.dense.bias True\n",
      "encoder.layer.16.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.16.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.16.bottleneck.attention.dense.weight True\n",
      "encoder.layer.16.bottleneck.attention.dense.bias True\n",
      "encoder.layer.16.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.16.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.0.output.dense.weight True\n",
      "encoder.layer.16.ffn.0.output.dense.bias True\n",
      "encoder.layer.16.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.1.output.dense.weight True\n",
      "encoder.layer.16.ffn.1.output.dense.bias True\n",
      "encoder.layer.16.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.16.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.16.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.16.ffn.2.output.dense.weight True\n",
      "encoder.layer.16.ffn.2.output.dense.bias True\n",
      "encoder.layer.16.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.16.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.17.attention.self.query.weight True\n",
      "encoder.layer.17.attention.self.query.bias True\n",
      "encoder.layer.17.attention.self.key.weight True\n",
      "encoder.layer.17.attention.self.key.bias True\n",
      "encoder.layer.17.attention.self.value.weight True\n",
      "encoder.layer.17.attention.self.value.bias True\n",
      "encoder.layer.17.attention.output.dense.weight True\n",
      "encoder.layer.17.attention.output.dense.bias True\n",
      "encoder.layer.17.attention.output.LayerNorm.bias True\n",
      "encoder.layer.17.attention.output.LayerNorm.weight True\n",
      "encoder.layer.17.intermediate.dense.weight True\n",
      "encoder.layer.17.intermediate.dense.bias True\n",
      "encoder.layer.17.output.dense.weight True\n",
      "encoder.layer.17.output.dense.bias True\n",
      "encoder.layer.17.output.LayerNorm.bias True\n",
      "encoder.layer.17.output.LayerNorm.weight True\n",
      "encoder.layer.17.output.bottleneck.dense.weight True\n",
      "encoder.layer.17.output.bottleneck.dense.bias True\n",
      "encoder.layer.17.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.17.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.17.bottleneck.input.dense.weight True\n",
      "encoder.layer.17.bottleneck.input.dense.bias True\n",
      "encoder.layer.17.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.17.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.17.bottleneck.attention.dense.weight True\n",
      "encoder.layer.17.bottleneck.attention.dense.bias True\n",
      "encoder.layer.17.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.17.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.0.output.dense.weight True\n",
      "encoder.layer.17.ffn.0.output.dense.bias True\n",
      "encoder.layer.17.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.1.output.dense.weight True\n",
      "encoder.layer.17.ffn.1.output.dense.bias True\n",
      "encoder.layer.17.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.17.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.17.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.17.ffn.2.output.dense.weight True\n",
      "encoder.layer.17.ffn.2.output.dense.bias True\n",
      "encoder.layer.17.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.17.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.18.attention.self.query.weight True\n",
      "encoder.layer.18.attention.self.query.bias True\n",
      "encoder.layer.18.attention.self.key.weight True\n",
      "encoder.layer.18.attention.self.key.bias True\n",
      "encoder.layer.18.attention.self.value.weight True\n",
      "encoder.layer.18.attention.self.value.bias True\n",
      "encoder.layer.18.attention.output.dense.weight True\n",
      "encoder.layer.18.attention.output.dense.bias True\n",
      "encoder.layer.18.attention.output.LayerNorm.bias True\n",
      "encoder.layer.18.attention.output.LayerNorm.weight True\n",
      "encoder.layer.18.intermediate.dense.weight True\n",
      "encoder.layer.18.intermediate.dense.bias True\n",
      "encoder.layer.18.output.dense.weight True\n",
      "encoder.layer.18.output.dense.bias True\n",
      "encoder.layer.18.output.LayerNorm.bias True\n",
      "encoder.layer.18.output.LayerNorm.weight True\n",
      "encoder.layer.18.output.bottleneck.dense.weight True\n",
      "encoder.layer.18.output.bottleneck.dense.bias True\n",
      "encoder.layer.18.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.18.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.18.bottleneck.input.dense.weight True\n",
      "encoder.layer.18.bottleneck.input.dense.bias True\n",
      "encoder.layer.18.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.18.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.18.bottleneck.attention.dense.weight True\n",
      "encoder.layer.18.bottleneck.attention.dense.bias True\n",
      "encoder.layer.18.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.18.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.0.output.dense.weight True\n",
      "encoder.layer.18.ffn.0.output.dense.bias True\n",
      "encoder.layer.18.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.1.output.dense.weight True\n",
      "encoder.layer.18.ffn.1.output.dense.bias True\n",
      "encoder.layer.18.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.18.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.18.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.18.ffn.2.output.dense.weight True\n",
      "encoder.layer.18.ffn.2.output.dense.bias True\n",
      "encoder.layer.18.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.18.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.19.attention.self.query.weight True\n",
      "encoder.layer.19.attention.self.query.bias True\n",
      "encoder.layer.19.attention.self.key.weight True\n",
      "encoder.layer.19.attention.self.key.bias True\n",
      "encoder.layer.19.attention.self.value.weight True\n",
      "encoder.layer.19.attention.self.value.bias True\n",
      "encoder.layer.19.attention.output.dense.weight True\n",
      "encoder.layer.19.attention.output.dense.bias True\n",
      "encoder.layer.19.attention.output.LayerNorm.bias True\n",
      "encoder.layer.19.attention.output.LayerNorm.weight True\n",
      "encoder.layer.19.intermediate.dense.weight True\n",
      "encoder.layer.19.intermediate.dense.bias True\n",
      "encoder.layer.19.output.dense.weight True\n",
      "encoder.layer.19.output.dense.bias True\n",
      "encoder.layer.19.output.LayerNorm.bias True\n",
      "encoder.layer.19.output.LayerNorm.weight True\n",
      "encoder.layer.19.output.bottleneck.dense.weight True\n",
      "encoder.layer.19.output.bottleneck.dense.bias True\n",
      "encoder.layer.19.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.19.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.19.bottleneck.input.dense.weight True\n",
      "encoder.layer.19.bottleneck.input.dense.bias True\n",
      "encoder.layer.19.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.19.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.19.bottleneck.attention.dense.weight True\n",
      "encoder.layer.19.bottleneck.attention.dense.bias True\n",
      "encoder.layer.19.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.19.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.0.output.dense.weight True\n",
      "encoder.layer.19.ffn.0.output.dense.bias True\n",
      "encoder.layer.19.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.1.output.dense.weight True\n",
      "encoder.layer.19.ffn.1.output.dense.bias True\n",
      "encoder.layer.19.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.19.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.19.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.19.ffn.2.output.dense.weight True\n",
      "encoder.layer.19.ffn.2.output.dense.bias True\n",
      "encoder.layer.19.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.19.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.20.attention.self.query.weight True\n",
      "encoder.layer.20.attention.self.query.bias True\n",
      "encoder.layer.20.attention.self.key.weight True\n",
      "encoder.layer.20.attention.self.key.bias True\n",
      "encoder.layer.20.attention.self.value.weight True\n",
      "encoder.layer.20.attention.self.value.bias True\n",
      "encoder.layer.20.attention.output.dense.weight True\n",
      "encoder.layer.20.attention.output.dense.bias True\n",
      "encoder.layer.20.attention.output.LayerNorm.bias True\n",
      "encoder.layer.20.attention.output.LayerNorm.weight True\n",
      "encoder.layer.20.intermediate.dense.weight True\n",
      "encoder.layer.20.intermediate.dense.bias True\n",
      "encoder.layer.20.output.dense.weight True\n",
      "encoder.layer.20.output.dense.bias True\n",
      "encoder.layer.20.output.LayerNorm.bias True\n",
      "encoder.layer.20.output.LayerNorm.weight True\n",
      "encoder.layer.20.output.bottleneck.dense.weight True\n",
      "encoder.layer.20.output.bottleneck.dense.bias True\n",
      "encoder.layer.20.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.20.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.20.bottleneck.input.dense.weight True\n",
      "encoder.layer.20.bottleneck.input.dense.bias True\n",
      "encoder.layer.20.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.20.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.20.bottleneck.attention.dense.weight True\n",
      "encoder.layer.20.bottleneck.attention.dense.bias True\n",
      "encoder.layer.20.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.20.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.0.output.dense.weight True\n",
      "encoder.layer.20.ffn.0.output.dense.bias True\n",
      "encoder.layer.20.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.1.output.dense.weight True\n",
      "encoder.layer.20.ffn.1.output.dense.bias True\n",
      "encoder.layer.20.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.20.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.20.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.20.ffn.2.output.dense.weight True\n",
      "encoder.layer.20.ffn.2.output.dense.bias True\n",
      "encoder.layer.20.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.20.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.21.attention.self.query.weight True\n",
      "encoder.layer.21.attention.self.query.bias True\n",
      "encoder.layer.21.attention.self.key.weight True\n",
      "encoder.layer.21.attention.self.key.bias True\n",
      "encoder.layer.21.attention.self.value.weight True\n",
      "encoder.layer.21.attention.self.value.bias True\n",
      "encoder.layer.21.attention.output.dense.weight True\n",
      "encoder.layer.21.attention.output.dense.bias True\n",
      "encoder.layer.21.attention.output.LayerNorm.bias True\n",
      "encoder.layer.21.attention.output.LayerNorm.weight True\n",
      "encoder.layer.21.intermediate.dense.weight True\n",
      "encoder.layer.21.intermediate.dense.bias True\n",
      "encoder.layer.21.output.dense.weight True\n",
      "encoder.layer.21.output.dense.bias True\n",
      "encoder.layer.21.output.LayerNorm.bias True\n",
      "encoder.layer.21.output.LayerNorm.weight True\n",
      "encoder.layer.21.output.bottleneck.dense.weight True\n",
      "encoder.layer.21.output.bottleneck.dense.bias True\n",
      "encoder.layer.21.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.21.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.21.bottleneck.input.dense.weight True\n",
      "encoder.layer.21.bottleneck.input.dense.bias True\n",
      "encoder.layer.21.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.21.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.21.bottleneck.attention.dense.weight True\n",
      "encoder.layer.21.bottleneck.attention.dense.bias True\n",
      "encoder.layer.21.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.21.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.0.output.dense.weight True\n",
      "encoder.layer.21.ffn.0.output.dense.bias True\n",
      "encoder.layer.21.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.1.output.dense.weight True\n",
      "encoder.layer.21.ffn.1.output.dense.bias True\n",
      "encoder.layer.21.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.21.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.21.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.21.ffn.2.output.dense.weight True\n",
      "encoder.layer.21.ffn.2.output.dense.bias True\n",
      "encoder.layer.21.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.21.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.22.attention.self.query.weight True\n",
      "encoder.layer.22.attention.self.query.bias True\n",
      "encoder.layer.22.attention.self.key.weight True\n",
      "encoder.layer.22.attention.self.key.bias True\n",
      "encoder.layer.22.attention.self.value.weight True\n",
      "encoder.layer.22.attention.self.value.bias True\n",
      "encoder.layer.22.attention.output.dense.weight True\n",
      "encoder.layer.22.attention.output.dense.bias True\n",
      "encoder.layer.22.attention.output.LayerNorm.bias True\n",
      "encoder.layer.22.attention.output.LayerNorm.weight True\n",
      "encoder.layer.22.intermediate.dense.weight True\n",
      "encoder.layer.22.intermediate.dense.bias True\n",
      "encoder.layer.22.output.dense.weight True\n",
      "encoder.layer.22.output.dense.bias True\n",
      "encoder.layer.22.output.LayerNorm.bias True\n",
      "encoder.layer.22.output.LayerNorm.weight True\n",
      "encoder.layer.22.output.bottleneck.dense.weight True\n",
      "encoder.layer.22.output.bottleneck.dense.bias True\n",
      "encoder.layer.22.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.22.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.22.bottleneck.input.dense.weight True\n",
      "encoder.layer.22.bottleneck.input.dense.bias True\n",
      "encoder.layer.22.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.22.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.22.bottleneck.attention.dense.weight True\n",
      "encoder.layer.22.bottleneck.attention.dense.bias True\n",
      "encoder.layer.22.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.22.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.0.output.dense.weight True\n",
      "encoder.layer.22.ffn.0.output.dense.bias True\n",
      "encoder.layer.22.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.1.output.dense.weight True\n",
      "encoder.layer.22.ffn.1.output.dense.bias True\n",
      "encoder.layer.22.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.22.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.22.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.22.ffn.2.output.dense.weight True\n",
      "encoder.layer.22.ffn.2.output.dense.bias True\n",
      "encoder.layer.22.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.22.ffn.2.output.LayerNorm.weight True\n",
      "encoder.layer.23.attention.self.query.weight True\n",
      "encoder.layer.23.attention.self.query.bias True\n",
      "encoder.layer.23.attention.self.key.weight True\n",
      "encoder.layer.23.attention.self.key.bias True\n",
      "encoder.layer.23.attention.self.value.weight True\n",
      "encoder.layer.23.attention.self.value.bias True\n",
      "encoder.layer.23.attention.output.dense.weight True\n",
      "encoder.layer.23.attention.output.dense.bias True\n",
      "encoder.layer.23.attention.output.LayerNorm.bias True\n",
      "encoder.layer.23.attention.output.LayerNorm.weight True\n",
      "encoder.layer.23.intermediate.dense.weight True\n",
      "encoder.layer.23.intermediate.dense.bias True\n",
      "encoder.layer.23.output.dense.weight True\n",
      "encoder.layer.23.output.dense.bias True\n",
      "encoder.layer.23.output.LayerNorm.bias True\n",
      "encoder.layer.23.output.LayerNorm.weight True\n",
      "encoder.layer.23.output.bottleneck.dense.weight True\n",
      "encoder.layer.23.output.bottleneck.dense.bias True\n",
      "encoder.layer.23.output.bottleneck.LayerNorm.bias True\n",
      "encoder.layer.23.output.bottleneck.LayerNorm.weight True\n",
      "encoder.layer.23.bottleneck.input.dense.weight True\n",
      "encoder.layer.23.bottleneck.input.dense.bias True\n",
      "encoder.layer.23.bottleneck.input.LayerNorm.bias True\n",
      "encoder.layer.23.bottleneck.input.LayerNorm.weight True\n",
      "encoder.layer.23.bottleneck.attention.dense.weight True\n",
      "encoder.layer.23.bottleneck.attention.dense.bias True\n",
      "encoder.layer.23.bottleneck.attention.LayerNorm.bias True\n",
      "encoder.layer.23.bottleneck.attention.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.0.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.0.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.0.output.dense.weight True\n",
      "encoder.layer.23.ffn.0.output.dense.bias True\n",
      "encoder.layer.23.ffn.0.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.0.output.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.1.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.1.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.1.output.dense.weight True\n",
      "encoder.layer.23.ffn.1.output.dense.bias True\n",
      "encoder.layer.23.ffn.1.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.1.output.LayerNorm.weight True\n",
      "encoder.layer.23.ffn.2.intermediate.dense.weight True\n",
      "encoder.layer.23.ffn.2.intermediate.dense.bias True\n",
      "encoder.layer.23.ffn.2.output.dense.weight True\n",
      "encoder.layer.23.ffn.2.output.dense.bias True\n",
      "encoder.layer.23.ffn.2.output.LayerNorm.bias True\n",
      "encoder.layer.23.ffn.2.output.LayerNorm.weight True\n",
      "embeddings.position_ids\n"
     ]
    }
   ],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.requires_grad)\n",
    "\n",
    "# for name, buffer in model.named_buffers():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading onnx model\n",
      "done creating trainingblock\n",
      "within \"with\" block\n",
      "inside mobilebertwithloss build\n",
      "training block initialized\n",
      "eval model created\n",
      "inference model done\n",
      "optimizer model done\n"
     ]
    }
   ],
   "source": [
    "class MobileBERTWithLoss(onnxblock.TrainingModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = onnxblock.loss.CrossEntropyLoss()\n",
    "\n",
    "    def build(self, loss_node_input_name):\n",
    "        print('inside mobilebertwithloss build')\n",
    "        return self.loss(loss_node_input_name)\n",
    "\n",
    "\n",
    "# Load the model from the exported inference ONNX file.\n",
    "onnx_model = onnx.load(f\"training_artifacts_dynamic/{model_name}.onnx\")\n",
    "print('done loading onnx model')\n",
    "eval_model = None\n",
    "optimizer_model = None\n",
    "\n",
    "training_block = MobileBERTWithLoss()\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         training_block.requires_grad(name)\n",
    "#     else:\n",
    "#         training_block.requires_grad(name, False)\n",
    "\n",
    "training_block.requires_grad('embeddings.position_ids', False)\n",
    "\n",
    "print('done creating trainingblock')\n",
    "\n",
    "inference_model_output_name = \"output\"\n",
    "with onnxblock.onnx_model(onnx_model) as model_accessor:\n",
    "    print('within \"with\" block')\n",
    "    loss_output_name = training_block(inference_model_output_name)\n",
    "    print('training block initialized')\n",
    "    eval_model = model_accessor.eval_model\n",
    "    print('eval model created')\n",
    "\n",
    "print('inference model done')\n",
    "\n",
    "optimizer_block = onnxblock.optim.AdamW()\n",
    "with onnxblock.onnx_model() as model_accessor:\n",
    "    optimizer_outputs = optimizer_block(training_block.parameters())\n",
    "    optimizer_model = model_accessor.model\n",
    "print('optimizer model done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnxblock.save_checkpoint(training_block.parameters(), f\"training_artifacts_dynamic/{model_name}.ckpt\")\n",
    "onnx.save(onnx_model, f\"training_artifacts_dynamic/{model_name}_training.onnx\")\n",
    "onnx.save(eval_model, f\"training_artifacts_dynamic/{model_name}_eval.onnx\")\n",
    "onnx.save(optimizer_model, f\"training_artifacts_dynamic/{model_name}_optimizer.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, pad_to_len):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "    # filter out empty strings\n",
    "    examples[\"text\"] = [sent for sent in examples[\"text\"] if len(sent) > 0]\n",
    "    return tokenizer(examples[\"text\"], return_special_tokens_mask=True, padding=\"max_length\", max_length=pad_to_len, truncation=True)\n",
    "\n",
    "def generate_tokens(corpus):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with a \"text\" feature.\n",
    "\n",
    "    Returns a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "    \"\"\"\n",
    "    # pad_to_len must be calculated before the batching happens to create consistent sizes in the resulting tensor\n",
    "    # pad_to_len = max([len(sent) for sent in corpus[\"text\"]])\n",
    "    pad_to_len = 150 # shortened for demonstration purposes\n",
    "    return corpus.map(tokenize_function, batched=True, fn_kwargs={\"pad_to_len\": pad_to_len})\n",
    "\n",
    "def generate_json_dict(token_dataset):\n",
    "    \"\"\"\n",
    "    Takes in a Dataset with the following features: text, input_ids, token_type_ids, attention_mask, special_tokens_mask\n",
    "\n",
    "    Basically changes the 2d Python lists into two fields: a shape & a flattened list, for easier conversion to OnnxValues\n",
    "\n",
    "    Returns a dictionary with the following keys: input_ids, input_size, token_type_ids, token_type_size, attention_mask, attention_mask_size, special_tokens_mask, special_tokens_size\n",
    "    \"\"\"\n",
    "    json_dict = {}\n",
    "    keys_to_convert = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"special_tokens_mask\"]\n",
    "\n",
    "    for key_name in keys_to_convert:\n",
    "        # add field for the shape of the tensor\n",
    "        json_dict[key_name + \"_shape\"] = [len(token_dataset[key_name]), len(token_dataset[key_name][0])]\n",
    "        # flatten list\n",
    "        json_dict[key_name] = [num for sent in token_dataset[key_name] for num in sent]\n",
    "    \n",
    "    return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|| 3/3 [00:00<00:00, 733.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"wikitext\" \n",
    "dataset_config = \"wikitext-2-v1\"\n",
    "# corpus = type DatasetDict with three Datasets: test, train, validation\n",
    "corpus = load_dataset(dataset_name, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "#corpus[\"train\"][\"text\"]\n",
    "# max([len(sent) for sent in corpus[\"train\"][\"text\"]])\n",
    "# 3837\n",
    "#len(corpus[\"train\"][\"text\"])\n",
    "# 36718\n",
    "\n",
    "train_test = generate_tokens(corpus[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23767\n",
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_test[\"input_ids\"]))\n",
    "# 36718\n",
    "print(len(train_test[\"input_ids\"][0]))\n",
    "# 3837\n",
    "\n",
    "max([len(sent) for sent in train_test[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b83d710dd1d17dd2.arrow\n",
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-f91b7e5c1178149a.arrow\n",
      "Loading cached processed dataset at /home/carolinezhu/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-aa24fc21c9608d06.arrow\n"
     ]
    }
   ],
   "source": [
    "test_tokens = generate_tokens(corpus[\"test\"])\n",
    "test_tokens = generate_json_dict(test_tokens)\n",
    "train_tokens = generate_tokens(corpus[\"train\"])\n",
    "train_tokens = generate_json_dict(train_tokens)\n",
    "validation_tokens = generate_tokens(corpus[\"validation\"])\n",
    "validation_tokens = generate_json_dict(validation_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all the tokens to a json file\n",
    "file_names = [\"test_tokens.json\", \"train_tokens.json\", \"validation_tokens.json\"]\n",
    "token_dicts = [test_tokens, train_tokens, validation_tokens]\n",
    "\n",
    "def write_dicts_to_files(file_names, dicts):\n",
    "    # assumes file_names and dicts are 2 lists w/ the same lengths\n",
    "    for i in range(len(file_names)):\n",
    "        with open(file_names[i], \"w\") as json_file:\n",
    "            json.dump(dicts[i], json_file)\n",
    "\n",
    "write_dicts_to_files(file_names, token_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
