{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will generate the offline training artifacts for the MNIST web demo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.training import artifacts\n",
    "import torch\n",
    "import onnx\n",
    "import io\n",
    "import netron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Offline Step\n",
    "\n",
    "To run your training loop, first you need to generate training, eval (optional) and optimizer graphs.\n",
    "\n",
    "We expect the users to have an onnx forward only model, you can generate this model with different ways, in this example we will be using torch.export to generate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch class that we will use to generate the graphs.\n",
    "class MNISTNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MNISTNet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, model_input):\n",
    "        out = self.fc1(model_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Create a MNISTNet instance.\n",
    "device = \"cpu\"\n",
    "batch_size, input_size, hidden_size, output_size = 64, 784, 500, 10\n",
    "pt_model = MNISTNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating forward only graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random input.\n",
    "model_inputs = (torch.randn(batch_size, input_size, device=device),)\n",
    "\n",
    "model_outputs = pt_model(*model_inputs)\n",
    "if isinstance(model_outputs, torch.Tensor):\n",
    "    model_outputs = [model_outputs]\n",
    "    \n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "f = io.BytesIO()\n",
    "torch.onnx.export(\n",
    "    pt_model,\n",
    "    model_inputs,\n",
    "    f,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=False,\n",
    "    training=torch.onnx.TrainingMode.TRAINING,\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    export_params=True,\n",
    "    keep_initializers_as_inputs=False,\n",
    ")\n",
    "onnx_model = onnx.load_model_from_string(f.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After creating forward only graph, we can now create the training graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_grad = [name for name, param in pt_model.named_parameters() if param.requires_grad]\n",
    "\n",
    "frozen_params = [name for name, param in pt_model.named_parameters() if not param.requires_grad]\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    loss=artifacts.LossType.CrossEntropyLoss,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    additional_output_names=output_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use netron to visualize the graphs.\n",
    "This is an example of how an eval graph looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netron.start(\"data/eval_model.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "672f1f04373ba0bfe81ddf50d232d84b9b6dccc610a78c59e8ffefd8db4edeac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
