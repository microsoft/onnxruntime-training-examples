{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Step - Generate the Training Artifacts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a pytorch model that has been pre-trained and export it to onnx. For this demo, we will use the `MobileNetV2` model for image classification. This model has been pretrained on the imagenet dataset that has data in 1000 categories.\n",
    "\n",
    "For our task of image classification, we want to only classify images in 4 classes. So, we change the last layer of the model to output 4 logits instead of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.mobilenet_v2(\n",
    "    weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# The original model is trained on imagenet which has 1000 classes.\n",
    "# For our image classification scenario, we need to classify among 4 categories.\n",
    "# So we need to change the last layer of the model to have 4 outputs.\n",
    "model.classifier[1] = torch.nn.Linear(1280, 4)\n",
    "\n",
    "# Export the model to ONNX.\n",
    "model_name = \"mobilenetv2\"\n",
    "torch.onnx.export(model, torch.randn(1, 3, 224, 224),\n",
    "                  f\"training_artifacts/{model_name}.onnx\", input_names=[\"input\"],\n",
    "                  output_names=[\"output\"], dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the mobilenetv2 model has been exported to ONNX, we need to generate the training artifacts:\n",
    "  - The training onnx `model = _gradient_(_optimize_(_stack_(inference onnx model, loss node)))`\n",
    "  - The eval onnx `model = _optimize_(_stack_(inference onnx model, loss node))`\n",
    "  - The optimizer onnx model - A new onnx model that takes in the model parameters as input, and updates them based on their gradients.\n",
    "  - The model parameter checkpoint file - Extracted and serialized model parameters.\n",
    "\n",
    "For this task, we will use the ONNX Runtime Python utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "\n",
    "# Define how the training model should look like.\n",
    "# In this case, we stack the loss function on top of the original model.\n",
    "class MobileNetV2BlockWithLoss(onnxblock.TrainingModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = onnxblock.loss.CrossEntropyLoss()\n",
    "\n",
    "    def build(self, loss_node_input_name):\n",
    "        return self.loss(loss_node_input_name)\n",
    "\n",
    "training_block = MobileNetV2BlockWithLoss()\n",
    "\n",
    "# This task is a transfer learning task. We want to only train the last layer of the model.\n",
    "# So, we mark parameters associated with other layers as non-trainable.\n",
    "for name, param in model.named_parameters():\n",
    "    if not (name == \"classifier.1.weight\" or name == \"classifier.1.bias\"):\n",
    "        training_block.requires_grad(name, False)\n",
    "\n",
    "# Load the model from the exported inference ONNX file.\n",
    "onnx_model = onnx.load(f\"training_artifacts/{model_name}.onnx\")\n",
    "eval_model = None\n",
    "optimizer_model = None\n",
    "\n",
    "inference_model_output_name = \"output\"\n",
    "with onnxblock.onnx_model(onnx_model) as model_accessor:\n",
    "    loss_output_name = training_block(inference_model_output_name)\n",
    "    eval_model = model_accessor.eval_model\n",
    "\n",
    "optimizer_block = onnxblock.optim.AdamW()\n",
    "with onnxblock.onnx_model() as model_accessor:\n",
    "    optimizer_outputs = optimizer_block(training_block.parameters())\n",
    "    optimizer_model = model_accessor.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All training artifacts are generated. We can now save them to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxblock.save_checkpoint(training_block.parameters(), f\"training_artifacts/{model_name}.ckpt\")\n",
    "onnx.save(onnx_model, f\"training_artifacts/{model_name}_training.onnx\")\n",
    "onnx.save(eval_model, f\"training_artifacts/{model_name}_eval.onnx\")\n",
    "onnx.save(optimizer_model, f\"training_artifacts/{model_name}_optimizer.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All training artifacts have been saved to the folder [training_artifacts](training_artifacts). These artifacts are now ready to be deployed on the edge device."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
