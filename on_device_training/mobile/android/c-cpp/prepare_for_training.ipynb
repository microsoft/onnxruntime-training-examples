{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Step - Generate the Training Artifacts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a pytorch model that has been pre-trained and export it to onnx. For this demo, we will use the `MobileNetV2` model for image classification. This model has been pretrained on the imagenet dataset that has data in 1000 categories.\n",
    "\n",
    "For our task of image classification, we want to only classify images in 4 classes. So, we change the last layer of the model to output 4 logits instead of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.mobilenet_v2(\n",
    "   weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# The original model is trained on imagenet which has 1000 classes.\n",
    "# For our image classification scenario, we need to classify among 4 categories.\n",
    "# So we need to change the last layer of the model to have 4 outputs.\n",
    "model.classifier[1] = torch.nn.Linear(1280, 4)\n",
    "\n",
    "# Export the model to ONNX.\n",
    "model_name = \"mobilenetv2\"\n",
    "torch.onnx.export(model, torch.randn(1, 3, 224, 224),\n",
    "                  f\"training_artifacts/{model_name}.onnx\",\n",
    "                  input_names=[\"input\"], output_names=[\"output\"],\n",
    "                  dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the mobilenetv2 model has been exported to ONNX, we need to generate the training artifacts:\n",
    "  - The training onnx `model = _gradient_(_optimize_(_stack_(inference onnx model, loss node)))`\n",
    "  - The eval onnx `model = _optimize_(_stack_(inference onnx model, loss node))`\n",
    "  - The optimizer onnx model - A new onnx model that takes in the model parameters as input, and updates them based on their gradients.\n",
    "  - The model parameter checkpoint file - Extracted and serialized model parameters.\n",
    "\n",
    "For this task, we will use the ONNX Runtime Python utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxruntime.training import artifacts\n",
    "\n",
    "# Load the onnx model.\n",
    "onnx_model = onnx.load(f\"training_artifacts/{model_name}.onnx\")\n",
    "\n",
    "requires_grad = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
    "frozen_params = [\n",
    "   param.name\n",
    "   for param in onnx_model.graph.initializer\n",
    "   if param.name not in requires_grad\n",
    "]\n",
    "\n",
    "\n",
    "# Generate the training artifacts.\n",
    "artifacts.generate_artifacts(\n",
    "   onnx_model,\n",
    "   requires_grad=requires_grad,\n",
    "   frozen_params=frozen_params,\n",
    "   loss=artifacts.LossType.CrossEntropyLoss,\n",
    "   optimizer=artifacts.OptimType.AdamW,\n",
    "   artifact_directory=\"training_artifacts\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All training artifacts have been saved to the folder [training_artifacts](training_artifacts). These artifacts are now ready to be deployed on the edge device."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
