{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we'll build a simple neural network in ORT and train it to recognize handwritten digits using the MNIST dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial has two sections:\n",
    "\n",
    "1. Offline Phase - Preparing training artifacts that will be consumed in the training phase.\n",
    "2. Training Phase - Train the model on the device.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries\n",
    "\n",
    "Make sure to install onnxruntime-training's nightly version.\n",
    "\n",
    "```pip install onnxruntime-training```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from onnxruntime.training.api import CheckpointState, Module, Optimizer\n",
    "from onnxruntime.training import artifacts\n",
    "from onnxruntime import InferenceSession\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import io\n",
    "import netron\n",
    "import evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Offline Step\n",
    "\n",
    "To run your training loop, first you need to generate training, eval (optional) and optimizer graphs.\n",
    "\n",
    "We expect the users to have an onnx forward only model, you can generate this model with different ways, in this example we will be using torch.export to generate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch class that we will use to generate the graphs.\n",
    "class MNISTNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MNISTNet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, model_input):\n",
    "        out = self.fc1(model_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Create a MNISTNet instance.\n",
    "device = \"cpu\"\n",
    "batch_size, input_size, hidden_size, output_size = 64, 784, 500, 10\n",
    "pt_model = MNISTNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating forward only graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random input.\n",
    "model_inputs = (torch.randn(batch_size, input_size, device=device),)\n",
    "\n",
    "model_outputs = pt_model(*model_inputs)\n",
    "if isinstance(model_outputs, torch.Tensor):\n",
    "    model_outputs = [model_outputs]\n",
    "    \n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "f = io.BytesIO()\n",
    "torch.onnx.export(\n",
    "    pt_model,\n",
    "    model_inputs,\n",
    "    f,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=False,\n",
    "    training=torch.onnx.TrainingMode.TRAINING,\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    export_params=True,\n",
    "    keep_initializers_as_inputs=False,\n",
    ")\n",
    "onnx_model = onnx.load_model_from_string(f.getvalue())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After creating forward only graph, we can now create the training graph.\n",
    "\n",
    "**Method 1:** \n",
    "\n",
    "The first step is creating a simple class that inherits from onnxblock.TrainingModel, and define the loss function.\n",
    "the build function defines the output of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class with a Loss function.\n",
    "class MNISTTrainingBlock(onnxblock.TrainingBlock):\n",
    "    def __init__(self):\n",
    "        super(MNISTTrainingBlock, self).__init__()\n",
    "        self.loss = onnxblock.loss.CrossEntropyLoss()\n",
    "\n",
    "    def build(self, output_name):\n",
    "        return self.loss(output_name), output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the onnx model with loss\n",
    "training_block = MNISTTrainingBlock()\n",
    "for param in onnx_model.graph.initializer:\n",
    "    print(param.name)\n",
    "    training_block.requires_grad(param.name, True)\n",
    "\n",
    "# Building training graph and eval graph.\n",
    "model_params = None\n",
    "with onnxblock.base(onnx_model):\n",
    "    _ = training_block(*[output.name for output in onnx_model.graph.output])\n",
    "    training_model, eval_model = training_block.to_model_proto()\n",
    "    model_params = training_block.parameters()\n",
    "\n",
    "# Building the optimizer graph\n",
    "optimizer_block = onnxblock.optim.AdamW()\n",
    "with onnxblock.empty_base() as accessor:\n",
    "    _ = optimizer_block(model_params)\n",
    "    optimizer_model = optimizer_block.to_model_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the files to use them later for the training.\n",
    "onnxblock.save_checkpoint(training_block.parameters(), \"data/checkpoint.ckpt\")\n",
    "onnx.save(training_model, \"data/training_model.onnx\")\n",
    "onnx.save(optimizer_model, \"data/optimizer_model.onnx\")\n",
    "onnx.save(eval_model, \"data/eval_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2:** \n",
    "\n",
    "Alternatively, you can use the generate_artifacts function provided by the onnxblock library. This function automatically generates a training graph based on the forward-only graph and the specified loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_grad = [name for name, param in pt_model.named_parameters() if param.requires_grad]\n",
    "\n",
    "frozen_params = [name for name, param in pt_model.named_parameters() if not param.requires_grad]\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    loss=artifacts.LossType.CrossEntropyLoss,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    artifact_directory=\"data\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use netron to visualize the graphs.\n",
    "This is an example of how an eval graph looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netron.start(\"data/eval_model.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data Preparation\n",
    "we're going to use datasets to load the MNIST Dataset and then we'll wrap it in a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "test_batch_size = 1000\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Initialize Module and Optimizer\n",
    "We will use the saved files to initialize the state, model and optimizer.\n",
    "Note that the eval graph is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint state.\n",
    "state = CheckpointState.load_checkpoint(\"data/checkpoint.ckpt\")\n",
    "\n",
    "# Create module.\n",
    "model = Module(\"data/training_model.onnx\", state, \"data/eval_model.onnx\")\n",
    "\n",
    "# Create optimizer.\n",
    "optimizer = Optimizer(\"data/optimizer_model.onnx\", model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Run Training and Testing Loops\n",
    "In this step we will define training and testing loops.\n",
    "The steps for training are simple :\n",
    "\n",
    "1 - set model to train mode : model.train()\n",
    "\n",
    "2 - prepare the input by making sure all inputs are numpy arrays\n",
    "\n",
    "3 - pass the input to the model : model(input)\n",
    "\n",
    "4 - call optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to convert logits to predictions.\n",
    "def get_pred(logits):\n",
    "    return np.argmax(logits, axis=1)\n",
    "\n",
    "# Training Loop :\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        forward_inputs = [data.reshape(len(data),784).numpy(),target.numpy().astype(np.int64)]\n",
    "        train_loss, _ = model(*forward_inputs)\n",
    "        optimizer.step()\n",
    "        model.lazy_reset_grad()\n",
    "        losses.append(train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1},Train Loss: {sum(losses)/len(losses):.4f}')\n",
    "\n",
    "# Test Loop :\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    metric = evaluate.load('accuracy')\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        forward_inputs = [data.reshape(len(data),784).numpy(),target.numpy().astype(np.int64)]\n",
    "        test_loss, logits = model(*forward_inputs)\n",
    "        metric.add_batch(references=target, predictions=get_pred(logits))\n",
    "        losses.append(test_loss)\n",
    "\n",
    "    metrics = metric.compute()\n",
    "    print(f'Epoch: {epoch+1}, Test Loss: {sum(losses)/len(losses):.4f}, Accuracy : {metrics[\"accuracy\"]:.2f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Run Inferencing\n",
    "In this step we will use InferenceSession to run inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_model_for_inferencing(\"data/inference_model.onnx\",[\"output\"])\n",
    "session = InferenceSession('data/inference_model.onnx',providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting one example from test list to try inference.\n",
    "data = next(iter(test_loader))[0][0]\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name \n",
    "output = session.run([output_name], {input_name: data.reshape(1,784).numpy()})\n",
    "\n",
    "# plotting the picture\n",
    "plt.imshow(data[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Predicted Label : \",get_pred(output[0]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "672f1f04373ba0bfe81ddf50d232d84b9b6dccc610a78c59e8ffefd8db4edeac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
